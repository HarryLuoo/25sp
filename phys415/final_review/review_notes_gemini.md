
- [10-Hour Thermal Physics Review Plan](#10-hour-thermal-physics-review-plan)
- [**Phase 1: Foundations of Statistical Mechanics**](#phase-1-foundations-of-statistical-mechanics)
  - [**1. Probability and the 1D Random Walk (Lecture 1)**](#1-probability-and-the-1d-random-walk-lecture-1)
    - [**1.1 Setup**](#11-setup)
    - [**1.2 Key Relationships**](#12-key-relationships)
    - [**1.3 Probability Distribution $P\_N(m)$**](#13-probability-distribution-p_nm)
    - [**1.4 Properties of Random Variables (General)**](#14-properties-of-random-variables-general)
    - [**1.5 Properties of the Binomial Distribution**](#15-properties-of-the-binomial-distribution)
  - [**2. Gaussian Approximation (Lecture 2)**](#2-gaussian-approximation-lecture-2)
    - [**2.1 Motivation**](#21-motivation)
    - [**2.2 Stirling's Approximation**](#22-stirlings-approximation)
    - [**2.3 Derivation Sketch**](#23-derivation-sketch)
    - [**2.4 Gaussian Distribution Result**](#24-gaussian-distribution-result)
  - [**3. Continuous Probability Distributions (Lecture 2)**](#3-continuous-probability-distributions-lecture-2)
    - [**3.1 Probability Density**](#31-probability-density)
    - [**3.2 Transformation of Variables**](#32-transformation-of-variables)
    - [**3.3 Example: X-component of a Random 2D Vector**](#33-example-x-component-of-a-random-2d-vector)
  - [**4. Statistical Description of Systems (Lecture 3)**](#4-statistical-description-of-systems-lecture-3)
    - [**4.1 Microscopic vs. Macroscopic**](#41-microscopic-vs-macroscopic)
    - [**4.2 Phase Space (Classical)**](#42-phase-space-classical)
    - [**4.3 Statistical Ensemble**](#43-statistical-ensemble)
    - [**4.4 Discretization of Phase Space**](#44-discretization-of-phase-space)
    - [**4.5 Fundamental Postulate (Equal a Priori Probabilities)**](#45-fundamental-postulate-equal-a-priori-probabilities)
    - [**4.6 Calculating Averages**](#46-calculating-averages)
  - [**5. Density of States (Lecture 4)**](#5-density-of-states-lecture-4)
    - [**5.1 Quantum Mechanical Description**](#51-quantum-mechanical-description)
    - [**5.2 Density of States Definitions**](#52-density-of-states-definitions)
    - [**5.3 Example: Classical Monatomic Ideal Gas**](#53-example-classical-monatomic-ideal-gas)
- [**Homework 1 Core Principles Review**](#homework-1-core-principles-review)
    - [**1. Basic Probability \& Counting (Problem 1a)**](#1-basic-probability--counting-problem-1a)
    - [**2. Binomial Distribution (Problems 1b, 1c, 3)**](#2-binomial-distribution-problems-1b-1c-3)
    - [**3. Random Walks \& Averages (Problem 1c, Problem 2)**](#3-random-walks--averages-problem-1c-problem-2)
    - [**4. Poisson Distribution (Problem 4)**](#4-poisson-distribution-problem-4)
    - [**5. Continuous Distributions \& Transformations (Problem 5)**](#5-continuous-distributions--transformations-problem-5)
- [**Phase 2: Thermal Interaction, Entropy, and Temperature**](#phase-2-thermal-interaction-entropy-and-temperature)
  - [**1. Interaction Between Macroscopic Bodies (Lecture 5)**](#1-interaction-between-macroscopic-bodies-lecture-5)
    - [**1.1 Macrostates and External Parameters**](#11-macrostates-and-external-parameters)
    - [**1.2 Types of Interactions Between Systems A and B**](#12-types-of-interactions-between-systems-a-and-b)
  - [**2. Quasi-static Processes, Work, Heat, and First Law (Lecture 6)**](#2-quasi-static-processes-work-heat-and-first-law-lecture-6)
    - [**2.1 Quasi-static Processes**](#21-quasi-static-processes)
    - [**2.2 Work and Heat in Statistical Terms**](#22-work-and-heat-in-statistical-terms)
    - [**2.3 First Law of Thermodynamics**](#23-first-law-of-thermodynamics)
    - [**2.4 Exact and Inexact Differentials**](#24-exact-and-inexact-differentials)
  - [**3. Thermal Interaction, Entropy, and Temperature (Lecture 7)**](#3-thermal-interaction-entropy-and-temperature-lecture-7)
    - [**3.1 Thermal Equilibrium**](#31-thermal-equilibrium)
    - [**3.2 Entropy Definition**](#32-entropy-definition)
    - [**3.3 Temperature Definition**](#33-temperature-definition)
    - [**3.4 Thermal Equilibrium Condition Revisited**](#34-thermal-equilibrium-condition-revisited)
    - [**3.5 Properties of Temperature**](#35-properties-of-temperature)
  - [**4. Entropy and Probability Distribution Sharpness (Lecture 8)**](#4-entropy-and-probability-distribution-sharpness-lecture-8)
    - [**4.1 Additivity of Entropy**](#41-additivity-of-entropy)
    - [**4.2 Sharpness of the Energy Distribution**](#42-sharpness-of-the-energy-distribution)
  - [**Homework 2 \& 3 Core Principles Review**](#homework-2--3-core-principles-review)
    - [**1. Phase Space, Microstates $\\Omega(E)$, and Density of States $\\omega(E)$**](#1-phase-space-microstates-omegae-and-density-of-states-omegae)
    - [**2. Entropy $S = \\ln \\Omega$ and Temperature $1/T = (\\partial S / \\partial E)$**](#2-entropy-s--ln-omega-and-temperature-1t--partial-s--partial-e)
    - [**3. First Law ($\\Delta E = Q - W$) and Work ($\\delta W = p dV$)**](#3-first-law-delta-e--q---w-and-work-delta-w--p-dv)
    - [**4. Equilibrium and Second Law ($\\Delta S\_{total} \\ge 0$)**](#4-equilibrium-and-second-law-delta-s_total-ge-0)
    - [**5. Probability Distributions Near Equilibrium (Fluctuations)**](#5-probability-distributions-near-equilibrium-fluctuations)
- [**Phase 3: Thermodynamic Relations and Ideal Gas (Lectures 9-11)**](#phase-3-thermodynamic-relations-and-ideal-gas-lectures-9-11)
  - [**1. General Interaction, Equilibrium, Thermodynamic Identity (Lecture 9)**](#1-general-interaction-equilibrium-thermodynamic-identity-lecture-9)
    - [**1.1 General Equilibrium Conditions**](#11-general-equilibrium-conditions)
    - [**1.2 Identifying $(\\partial S / \\partial V)\_E$**](#12-identifying-partial-s--partial-v_e)
    - [**1.3 Thermodynamic Identity**](#13-thermodynamic-identity)
    - [**1.4 Relation $T dS = Q$ for Quasi-static Processes**](#14-relation-t-ds--q-for-quasi-static-processes)
  - [**2. Recap of Laws, Heat Capacity, Extensive/Intensive (Lecture 10)**](#2-recap-of-laws-heat-capacity-extensiveintensive-lecture-10)
    - [**2.1 Laws of Thermodynamics (Statistical Basis)**](#21-laws-of-thermodynamics-statistical-basis)
    - [**2.2 Heat Capacities**](#22-heat-capacities)
    - [**2.3 Extensive and Intensive Quantities**](#23-extensive-and-intensive-quantities)
  - [**3. Applications to Ideal Gas (Lecture 11)**](#3-applications-to-ideal-gas-lecture-11)
    - [**3.1 Ideal Gas Properties**](#31-ideal-gas-properties)
    - [**3.2 $E$ depends only on $T$ for Ideal Gas (Macroscopic Derivation)**](#32-e-depends-only-on-t-for-ideal-gas-macroscopic-derivation)
    - [**3.3 Heat Capacities of Ideal Gas**](#33-heat-capacities-of-ideal-gas)
    - [**3.4 Adiabatic Process for Ideal Gas ($Q=0$)**](#34-adiabatic-process-for-ideal-gas-q0)
  - [**Homework 4 Core Principles Review**](#homework-4-core-principles-review)
    - [**1. General Thermodynamic Relations and Equations of State (Problem 1)**](#1-general-thermodynamic-relations-and-equations-of-state-problem-1)
    - [**2. Entropy of Mixing and Gibbs Paradox (Problem 2)**](#2-entropy-of-mixing-and-gibbs-paradox-problem-2)
    - [**3. Adiabatic Processes for Ideal Gas (Problem 3)**](#3-adiabatic-processes-for-ideal-gas-problem-3)
    - [**4. Cyclic Processes, Work, Heat (Problems 4, 5)**](#4-cyclic-processes-work-heat-problems-4-5)
    - [**5. Adiabatic Processes in Atmosphere (Problem 6)**](#5-adiabatic-processes-in-atmosphere-problem-6)
- [**Phase 4: Thermodynamic Potentials and Applications (Lectures 12-16)**](#phase-4-thermodynamic-potentials-and-applications-lectures-12-16)
  - [**1. Thermodynamic Potentials (Lecture 12)**](#1-thermodynamic-potentials-lecture-12)
    - [**1.1 Helmholtz Free Energy ($F$)**](#11-helmholtz-free-energy-f)
    - [**1.2 Enthalpy ($H$)**](#12-enthalpy-h)
    - [**1.3 Gibbs Free Energy ($G$)**](#13-gibbs-free-energy-g)
  - [**2. Equilibrium Conditions and Maxwell Relations (Lecture 13)**](#2-equilibrium-conditions-and-maxwell-relations-lecture-13)
    - [**2.1 Equilibrium Conditions (Minimization Principles)**](#21-equilibrium-conditions-minimization-principles)
    - [**2.2 Maxwell Relations**](#22-maxwell-relations)
    - [**2.3 Application: $C\_p - C\_V$ Relation**](#23-application-c_p---c_v-relation)
  - [**3. Free Expansion and Joule-Thomson Process (Lectures 14, 15)**](#3-free-expansion-and-joule-thomson-process-lectures-14-15)
    - [**3.1 Free Expansion (Joule Expansion)**](#31-free-expansion-joule-expansion)
    - [**3.2 Joule-Thomson Process (Throttling)**](#32-joule-thomson-process-throttling)
  - [**4. Heat Engines and Refrigerators (Lecture 16)**](#4-heat-engines-and-refrigerators-lecture-16)
    - [**4.1 Heat Engines**](#41-heat-engines)
    - [**4.2 Refrigerators**](#42-refrigerators)
    - [**4.3 Carnot Cycle**](#43-carnot-cycle)
  - [**Homework 5 Core Principles Review**](#homework-5-core-principles-review)
    - [**1. Thermodynamic Potentials and Maxwell Relations (Problem 1)**](#1-thermodynamic-potentials-and-maxwell-relations-problem-1)
    - [**2. Joule-Thomson Process and Inversion Curve (Problem 2)**](#2-joule-thomson-process-and-inversion-curve-problem-2)
    - [**3. Refrigerators/Heat Pumps and Second Law Limits (Problem 3)**](#3-refrigeratorsheat-pumps-and-second-law-limits-problem-3)
    - [**4. Heat Engines with Finite Reservoirs (Problem 4)**](#4-heat-engines-with-finite-reservoirs-problem-4)
    - [**5. Statistical Interpretation of Second Law (Problem 5)**](#5-statistical-interpretation-of-second-law-problem-5)
    - [**6. Idealized Engine Cycles (Gasoline Engine) (Problem 6)**](#6-idealized-engine-cycles-gasoline-engine-problem-6)
    - [**7. Second Law Limits on Coupled Engines/Refrigerators (Problem 7)**](#7-second-law-limits-on-coupled-enginesrefrigerators-problem-7)
- [**Phase 5: Canonical and Grand Canonical Ensembles (Lectures 18-21)**](#phase-5-canonical-and-grand-canonical-ensembles-lectures-18-21)
  - [**1. Canonical Ensemble (CE) (Lectures 18, 19)**](#1-canonical-ensemble-ce-lectures-18-19)
    - [**1.1 Motivation and Setup**](#11-motivation-and-setup)
    - [**1.2 Derivation of the Canonical Distribution**](#12-derivation-of-the-canonical-distribution)
    - [**1.3 Partition Function ($Z$)**](#13-partition-function-z)
    - [**1.4 Averages in the CE**](#14-averages-in-the-ce)
  - [**2. Connection to Thermodynamics (CE) (Lectures 19, 20)**](#2-connection-to-thermodynamics-ce-lectures-19-20)
    - [**2.1 Helmholtz Free Energy ($F$)**](#21-helmholtz-free-energy-f)
    - [**2.2 Equivalence of Ensembles**](#22-equivalence-of-ensembles)
  - [**3. Grand Canonical Ensemble (GCE) (Lecture 21)**](#3-grand-canonical-ensemble-gce-lecture-21)
    - [**3.1 Motivation and Setup**](#31-motivation-and-setup)
    - [**3.2 Chemical Potential ($\\mu$)**](#32-chemical-potential-mu)
    - [**3.3 Derivation of the Grand Canonical Distribution**](#33-derivation-of-the-grand-canonical-distribution)
    - [**3.4 Grand Partition Function ($\\mathcal{Z}$)**](#34-grand-partition-function-mathcalz)
    - [**3.5 Grand Potential ($\\Phi$)**](#35-grand-potential-phi)
  - [**Summary of Statistical Ensembles**](#summary-of-statistical-ensembles)
- [**Phase 6: Classical \& Quantum Statistics (Lectures 22-25, 27)**](#phase-6-classical--quantum-statistics-lectures-22-25-27)
  - [**1. Ideal Gas Revisited (Canonical Ensemble) \& Gibbs Paradox (Lecture 22)**](#1-ideal-gas-revisited-canonical-ensemble--gibbs-paradox-lecture-22)
    - [**1.1 Classical Partition Function ($Z'$) - Initial Attempt**](#11-classical-partition-function-z---initial-attempt)
    - [**1.2 Thermodynamics from $Z'$ and the Gibbs Paradox**](#12-thermodynamics-from-z-and-the-gibbs-paradox)
    - [**1.3 Resolution: Indistinguishable Particles and Correct Partition Function ($Z$)**](#13-resolution-indistinguishable-particles-and-correct-partition-function-z)
  - [**2. Validity of Classical Limit \& Equipartition Theorem (Lecture 23)**](#2-validity-of-classical-limit--equipartition-theorem-lecture-23)
    - [**2.1 Validity of Classical Approximation**](#21-validity-of-classical-approximation)
    - [**2.2 Equipartition Theorem (Classical)**](#22-equipartition-theorem-classical)
  - [**3. Introduction to Quantum Statistics (Lecture 27)**](#3-introduction-to-quantum-statistics-lecture-27)
    - [**3.1 Identical Particles and Quantum States**](#31-identical-particles-and-quantum-states)
    - [**3.2 Occupation Numbers**](#32-occupation-numbers)
    - [**3.3 Partition Function in Terms of Occupation Numbers (Canonical)**](#33-partition-function-in-terms-of-occupation-numbers-canonical)


# 10-Hour Thermal Physics Review Plan

Here's a possible breakdown:

**Phase 1: Foundations of Statistical Mechanics (Approx. 1.5 hours)**

*   **Topics:** Probability concepts, random walks, binomial distribution, Gaussian approximation, introduction to statistical description (microstates, phase space), fundamental postulate (equal a priori probabilities), density of states (classical and quantum).
*   **Lectures Covered (Approx.):** 1 - 4
*   **Key Goals:** Solidify understanding of probability distributions (Binomial, Gaussian). Grasp the concept of microstates, macrostates, phase space, and the fundamental assumption of statistical mechanics. Understand how to count states (Ω(E), ω(E)).
*   **Reif Refs:** Ch 1, 2.1-2.5

**Phase 2: Thermal Interaction and Entropy (Approx. 2.0 hours)**

*   **Topics:** Interaction between macroscopic systems (thermal, mechanical), First Law of Thermodynamics (energy conservation, heat, work), quasi-static processes, exact/inexact differentials, definition of entropy (S = ln Ω), temperature (1/T = ∂S/∂E), approach to equilibrium, Second Law introduction (entropy increase).
*   **Lectures Covered (Approx.):** 5 - 8
*   **Key Goals:** Understand the First Law from a statistical perspective. Define and understand entropy and temperature statistically. Analyze thermal equilibrium and the concept of entropy maximization.
*   **Reif Refs:** 2.6-2.11, 3.1-3.7

**Phase 3: Thermodynamic Relations and Ideal Gas (Approx. 1.5 hours)**

*   **Topics:** Thermodynamic identity (dE = TdS - pdV), conditions for thermal and mechanical equilibrium (T1=T2, p1=p2), Laws of Thermodynamics recap, heat capacities (CV, Cp), applications to ideal gas (isothermal, adiabatic processes, E(T), pV=NT derivation).
*   **Lectures Covered (Approx.):** 9 - 11
*   **Key Goals:** Master the thermodynamic identity and its implications for equilibrium. Apply concepts to the ideal gas model, deriving key results like heat capacities and process equations. Understand extensive/intensive quantities.
*   **Reif Refs:** 3.2, 3.8-3.12, 4.4, 4.7, 5.1-5.4
*   *(Note: Covers material up to Midterm 1)*

**Phase 4: Thermodynamic Potentials and Applications (Approx. 2.0 hours)**

*   **Topics:** Helmholtz Free Energy (F), Enthalpy (H), Gibbs Free Energy (G), Maxwell relations, Cp-Cv relation derivation, free expansion (Joule), Joule-Thomson (throttling) process, heat engines, refrigerators, Carnot cycle.
*   **Lectures Covered (Approx.):** 12 - 16
*   **Key Goals:** Understand the utility of different thermodynamic potentials and their natural variables. Derive and apply Maxwell relations. Analyze key thermodynamic processes and cycles (free expansion, throttling, Carnot).
*   **Reif Refs:** 5.5, 5.8-5.12, 8.1-8.3
*   *(Note: Significant portion of Midterm 2 material)*

**Phase 5: Canonical and Grand Canonical Ensembles (Approx. 1.5 hours)**

*   **Topics:** Canonical Ensemble (fixed T, V, N), Boltzmann factor, partition function Z, connection to Helmholtz free energy (F = -T ln Z), calculating averages (E, p), fluctuations (energy), Grand Canonical Ensemble (fixed T, V, μ), grand partition function Z, connection to grand potential Φ.
*   **Lectures Covered (Approx.):** 18 - 21
*   **Key Goals:** Understand the setup and utility of the canonical and grand canonical ensembles. Master the concept and calculation of the partition function (Z and Z) and their relation to thermodynamic potentials (F and Φ). Calculate averages and fluctuations.
*   **Reif Refs:** 6.1-6.7, 6.9

**Phase 6: Classical & Quantum Statistics (Approx. 1.5 hours)**

*   **Topics:** Ideal Gas revisited (using Z), Gibbs paradox, identical particles (N! correction), validity of classical limit (nλ³ << 1), equipartition theorem, introduction to quantum statistics (BE/FD), occupation numbers, Pauli exclusion.
*   **Lectures Covered (Approx.):** 22 - 25, 27
*   **Key Goals:** Re-derive ideal gas properties using Z. Understand the Gibbs paradox and the need for the N! factor. Know the conditions for classical vs. quantum regimes. Understand the equipartition theorem and its limitations. Grasp the fundamental difference between Bosons and Fermions.
*   **Reif Refs:** 7.1-7.6, 9.1-9.2
*   *(Note: Completes Midterm 2 material)*

**Phase 7: Applications of Quantum Statistics (Approx. 1.0 hour)**

*   **Topics:** Degenerate Fermi gas (T=0 properties, Fermi energy ϵF, low T heat capacity CV ∝ T), Bose-Einstein Condensation (critical temperature Tc, condensate fraction), Black-body radiation (Planck distribution, Stefan-Boltzmann law).
*   **Lectures Covered (Approx.):** 28, 30 - 36 (selection based on key results)
*   **Key Goals:** Understand the key phenomena arising from quantum statistics: Fermi pressure and linear heat capacity in metals, the macroscopic occupation of the ground state in BEC, and the spectrum of blackbody radiation.
*   **Reif Refs:** 9.3-9.17 (selective reading focusing on main results)

---

This plan allocates roughly 10 hours. Remember to be flexible. If you're comfortable with a topic, move faster; if something is challenging, spend a bit more time. The key is active recall and understanding the connections between concepts.

Now, shall we start generating the summarized review notes based on this plan, beginning with Phase 1 (Lectures 1-4)?

---

Okay, let's begin with Phase 1, covering the foundational concepts from approximately Lectures 1-4.

\format

# **Phase 1: Foundations of Statistical Mechanics**

This section covers basic probability, the random walk model, the introduction to the statistical description of systems, the fundamental postulate, and the concept of density of states.

## **1. Probability and the 1D Random Walk (Lecture 1)**

### **1.1 Setup**

*   We consider a walker starting at $x=0$.
*   The walker takes $N$ steps, each of length $l$.
*   Each step is independent.
*   Probability of stepping right is $p$.
*   Probability of stepping left is $q = 1-p$.
*   After $N$ steps, the position is $x = ml$, where $m$ is an integer.

### **1.2 Key Relationships**

*   Let $n_1$ be the number of steps to the right and $n_2$ be the number of steps to the left.
*   Total steps: $$ N = n_1 + n_2 $$
*   Final position displacement (in units of $l$): $$ m = n_1 - n_2 $$
*   Solving for $n_1$ and $n_2$: $$ n_1 = \frac{N+m}{2}, \quad n_2 = \frac{N-m}{2} $$
*   Note: $N$ and $m$ must have the same parity ($N-m = 2n_2$ must be even). The range is $-N \le m \le N$.

### **1.3 Probability Distribution $P_N(m)$**

*   The probability of any *specific* sequence of $n_1$ right steps and $n_2$ left steps is $p^{n_1} q^{n_2}$.
*   The number of distinct sequences with $n_1$ right and $n_2$ left steps is given by the binomial coefficient: $$ \binom{N}{n_1} = \frac{N!}{n_1!(N-n_1)!} = \frac{N!}{n_1!n_2!} $$
*   The total probability of ending up at position $m$ after $N$ steps is the product of the number of ways and the probability of one specific way:
    $$
    \boxed{ P_N(m) = \frac{N!}{n_1!n_2!} p^{n_1} q^{n_2} = \frac{N!}{\left(\frac{N+m}{2}\right)! \left(\frac{N-m}{2}\right)!} p^{(N+m)/2} (1-p)^{(N-m)/2} }
    $$ This is the **Binomial Distribution**.

### **1.4 Properties of Random Variables (General)**

*   For a discrete random variable $X$ taking values $x_i$ with probabilities $P(x_i)$:
*   Mean (Average): $$ \bar{X} = \sum_i P(x_i) x_i $$
*   Mean of a function $f(X)$: $$ \overline{f(X)} = \sum_i P(x_i) f(x_i) $$
*   Variance: $$ \text{Var}(X) = \sigma_X^2 = \overline{(X - \bar{X})^2} = \sum_i P(x_i)(x_i - \bar{X})^2 = \overline{X^2} - (\bar{X})^2 $$
*   Root-Mean-Square (RMS) Deviation (Standard Deviation): $$ \Delta X_{rms} = \sigma_X = \sqrt{\overline{(X - \bar{X})^2}} $$

### **1.5 Properties of the Binomial Distribution**

*   Applying to the number of right steps $n_1$:
    *   Mean: $\bar{n_1} = Np$
    *   Variance: $\sigma_{n_1}^2 = Npq$
    *   RMS Deviation: $\Delta n_{1,rms} = \sqrt{Npq}$
*   Relative Width: $$ \frac{\Delta n_{1,rms}}{\bar{n_1}} = \frac{\sqrt{Npq}}{Np} = \sqrt{\frac{q}{p}} \frac{1}{\sqrt{N}} $$
*   **Key Insight:** As $N \to \infty$, the relative width approaches 0. The distribution becomes sharply peaked around the mean.

## **2. Gaussian Approximation (Lecture 2)**

### **2.1 Motivation**

*   For large $N$, calculating factorials in the binomial distribution is impractical. We approximate it using a continuous distribution.
*   Assume $N \gg 1$, $n_1 \gg 1$, $n_2 \gg 1$.

### **2.2 Stirling's Approximation**

*   For large $M$: $$ \ln M! \approx M \ln M - M + \frac{1}{2} \ln(2\pi M) $$
*   A simpler version often suffices: $\ln M! \approx M \ln M - M$.

### **2.3 Derivation Sketch**

1.  Take the logarithm of $P_N(n_1)$: $\ln P_N(n_1) = \ln N! - \ln n_1! - \ln n_2! + n_1 \ln p + n_2 \ln q$.
2.  Apply Stirling's approximation to all factorials.
3.  Define $x = n_1/N$ and express $\ln P_N$ in terms of $x$. Define $f(x) = - [x \ln x + (1-x) \ln(1-x)] + [x \ln p + (1-x) \ln q]$. This term, when maximized, gives the most probable state.
4.  Find the maximum of $f(x)$ by setting $f'(x)=0$. This occurs at $x = \tilde{x} = p$, corresponding to the mean $\tilde{n}_1 = Np$.
5.  Taylor expand $f(x)$ around the maximum $\tilde{x}=p$ up to the second order: $f(x) \approx f(p) + f'(p)(x-p) + \frac{1}{2} f''(p)(x-p)^2$.
6.  $f(p) = 0$ and $f'(p)=0$. Calculate $f''(p) = -1/(pq)$.
7.  Substitute $x - p = (n_1 - Np)/N$.
8.  The expansion becomes $\ln P_N(n_1) \approx \ln P_N(\tilde{n}_1) - N \frac{1}{2pq} \left(\frac{n_1 - Np}{N}\right)^2 = \ln P_N(\tilde{n}_1) - \frac{(n_1 - Np)^2}{2Npq}$.
9.  Use the normalization constant derived from the approximation of the prefactor $\frac{N!}{n_1!n_2!}$ which leads to $\frac{1}{\sqrt{2\pi Npq}}$.

### **2.4 Gaussian Distribution Result**

*   Defining the mean $\mu = Np$ and variance $\sigma^2 = Npq$:
    $$
    \boxed{ P_N(n_1) \approx \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{(n_1 - \mu)^2}{2\sigma^2}} }
    $$ This is a Gaussian (or Normal) distribution. It's a continuous distribution approximating the discrete binomial for large $N$.

## **3. Continuous Probability Distributions (Lecture 2)**

### **3.1 Probability Density**

*   For a continuous random variable $X$, we define the probability density $P(x)$ such that $P(x)dx$ is the probability of finding the variable in the range $[x, x+dx]$.
*   Normalization: $\int P(x) dx = 1$ (integral over the entire domain).
*   Mean: $\bar{X} = \int x P(x) dx$.
*   Variance: $\sigma^2 = \int (x-\bar{X})^2 P(x) dx = \overline{X^2} - (\bar{X})^2$.

### **3.2 Transformation of Variables**

*   If $y = f(x)$, the probability density $P_y(y)$ is related to $P_x(x)$ by conservation of probability: $P_y(y) |dy| = \sum_i P_x(x_i) |dx_i|$, where the sum is over all $x_i$ such that $f(x_i) = y$.
*   This leads to: $$ P_y(y) = \sum_i P_x(x_i) \left| \frac{dx}{dy} \right|_{x=x_i} $$

### **3.3 Example: X-component of a Random 2D Vector**

*   Consider a vector $\vec{B}$ of fixed length $B$ with a random orientation $\theta$ (uniform in $[0, 2\pi]$), so $P_\theta(\theta) = 1/(2\pi)$.
*   The x-component is $B_x = B \cos \theta$.
*   Using the transformation rule, we find the probability density for $B_x$ (for $-B < B_x < B$):
    $$ P_{B_x}(B_x) = \frac{1}{\pi \sqrt{B^2 - B_x^2}} $$
*   This distribution peaks near $B_x = \pm B$.

## **4. Statistical Description of Systems (Lecture 3)**

### **4.1 Microscopic vs. Macroscopic**

*   **Microscopic:** Full description of every particle (positions, momenta). Governed by mechanics (Classical or Quantum). For $N \sim 10^{23}$, this is intractable and unnecessary.
*   **Macroscopic:** Description using a few bulk variables (Energy $E$, Volume $V$, Pressure $p$, Temperature $T$, etc.).

### **4.2 Phase Space (Classical)**

*   A system with $S$ degrees of freedom is described by $S$ generalized coordinates $q = (q_1, ..., q_S)$ and $S$ generalized momenta $p = (p_1, ..., p_S)$.
*   The **microstate** of the system at time $t$ is a point $(q(t), p(t))$ in the $2S$-dimensional **phase space**.
*   Example: $N$ particles in 3D. $S=3N$. Phase space dimension is $6N$.
*   Evolution: The state evolves according to Hamilton's equations: $\dot{q}_i = \partial H/\partial p_i$, $\dot{p}_i = -\partial H/\partial q_i$. The path is a trajectory in phase space.

### **4.3 Statistical Ensemble**

*   Instead of following one system, consider a large number $\mathcal{N} \gg 1$ of identical systems prepared under the same macroscopic conditions (e.g., same $E, V, N$). This collection is an **ensemble**.
*   We are interested in the probability $P(\mu_i)$ that a system chosen randomly from the ensemble is in a specific microstate $\mu_i$.

### **4.4 Discretization of Phase Space**

*   To count microstates, we conceptually divide phase space into small cells of volume $\delta q_1...\delta q_S \delta p_1...\delta p_S = h_0^S$.
*   Each cell represents one microstate. $h_0$ has units of action (related to Planck's constant $h$ in QM).

### **4.5 Fundamental Postulate (Equal a Priori Probabilities)**

*   **Postulate:** For an isolated system in equilibrium, all accessible microstates are equally likely.
*   An **isolated system** has fixed energy $E$ (usually within a small range $[E, E+\delta E]$), fixed volume $V$, and fixed particle number $N$.
*   **Accessible microstates:** Those microstates compatible with the macroscopic constraints (e.g., energy in $[E, E+\delta E]$).
*   Let $\Omega(E, V, N)$ be the total number of accessible microstates.
*   The probability of finding the system in any *one* specific accessible microstate $\mu_i$ is:
    $$
    \boxed{ P(\mu_i) = \frac{1}{\Omega(E, V, N)} }
    $$ if $\mu_i$ is accessible, and $P(\mu_i)=0$ otherwise.
*   **Equilibrium:** The state where macroscopic properties are time-independent. The postulate applies to systems in equilibrium.

### **4.6 Calculating Averages**

*   The average value (ensemble average) of a macroscopic quantity $Y$ that takes value $Y(\mu_i)$ in microstate $\mu_i$ is: $$ \bar{Y} = \sum_{\mu_i} P(\mu_i) Y(\mu_i) = \frac{1}{\Omega(E)} \sum_{\mu_i \text{ accessible}} Y(\mu_i) $$
*   Often grouped by the value $y_k$ the observable takes: Let $\Omega(E; y_k)$ be the number of accessible states where $Y=y_k$. $$ \bar{Y} = \sum_k y_k P(Y=y_k) = \sum_k y_k \frac{\Omega(E; y_k)}{\Omega(E)} = \frac{1}{\Omega(E)} \sum_k y_k \Omega(E; y_k) $$

## **5. Density of States (Lecture 4)**

### **5.1 Quantum Mechanical Description**

*   Microstates correspond to quantum states $\Psi$, often specified by a set of quantum numbers (e.g., $n$ for particle in a box, $n_1, ..., n_N$ for N oscillators).
*   Energy levels are often discrete.
*   **Fundamental Postulate (QM):** For an isolated system in equilibrium, all accessible quantum states are equally likely.
*   $\Omega(E)$ = number of quantum states with energy in range $[E, E+\delta E]$ (or number of degenerate states if energy levels are discrete and we consider exactly energy $E$).

### **5.2 Density of States Definitions**

*   $\Omega(E, V, N, \delta E)$: Number of microstates between $E$ and $E+\delta E$. $\delta E$ is assumed small macroscopically but large microscopically (containing many states).
*   $\Phi(E, V, N)$: Total number of microstates with energy $\le E$.
*   $\omega(E, V, N)$: Density of states. Defined such that $\Omega(E) = \omega(E) \delta E$.
*   Relationship: $$ \omega(E) = \frac{d\Phi(E)}{dE} $$

### **5.3 Example: Classical Monatomic Ideal Gas**

*   $N$ particles in volume $V$. Energy $H = \sum_{i=1}^N \frac{|\vec{p}_i|^2}{2m}$. No potential energy $U(q)=0$.
*   We need the volume of phase space between $E$ and $E+\delta E$.
*   The coordinate part integrates to $V^N$.
*   The momentum part involves the volume of a hyperspherical shell in $3N$ dimensions. The condition $E \le \sum p_i^2/(2m) \le E+\delta E$ defines the shell.
*   The volume of a $D$-dimensional sphere of radius $R$ is $V_D(R) = C_D R^D$. Here $D=3N$ and $R^2 = \sum p_i^2 = 2mE$.
*   Momentum space volume $\Phi_p(E)$ with momentum magnitude $\le \sqrt{2mE}$ is $\Phi_p(E) \propto ( (2mE)^{1/2} )^{3N} \propto E^{3N/2}$.
*   The number of states $\Phi(E) \propto V^N \Phi_p(E) \propto V^N E^{3N/2}$.
*   Density of states: $\omega(E) = d\Phi/dE \propto V^N (3N/2) E^{3N/2 - 1}$.
*   For large $N$, $3N/2 - 1 \approx 3N/2$.
    $$
    \boxed{ \omega(E) \propto V^N E^{3N/2} } \quad (N \gg 1)
    $$
*   **Key Observation:** $\omega(E)$ and $\Omega(E)$ are extremely rapidly increasing functions of $E$ and $N$.

This concludes the summary for Phase 1. Let me know when you're ready for Phase 2 (Lectures 5-8).

---

Okay, let's go through the HW1 solutions efficiently by identifying the core principles used in each problem, linking them back to the Phase 1 topics.

\format

# **Homework 1 Core Principles Review**

Here's a breakdown of the problems based on the fundamental concepts they illustrate:

### **1. Basic Probability & Counting (Problem 1a)**

*   **Problem:** Probability of sum ≤ 6 with three dice.
*   **Core Principle:** Fundamental definition of probability for discrete, equally likely outcomes:
    $$ P(\text{Event}) = \frac{\text{Number of Favorable Outcomes}}{\text{Total Number of Possible Outcomes}} $$
*   **Method:**
    1.  Determine the total number of outcomes (sample space size): $6 \times 6 \times 6 = 216$.
    2.  Systematically enumerate all combinations of three dice rolls that sum to 6 or less. Be careful to account for permutations (e.g., (1,1,2) is distinct from (1,2,1) and (2,1,1) unless the dice are indistinguishable, but standard dice problems assume distinguishability or account for it as done in the solution by multiplying by the number of ways, e.g., (1,1,2) x 3). The solution groups combinations and multiplies by permutations: (1,1,1)x1, (1,1,2)x3, (1,2,2)x3, (2,2,2)x1, (3,2,1)x6, (3,1,1)x3, (4,1,1)x3. Total = 1+3+3+1+6+3+3 = 20.
    3.  Calculate the probability: $20 / 216 = 5 / 54$.
*   **Connection to Phase 1:** This uses the most basic probability concepts introduced before discussing distributions.

### **2. Binomial Distribution (Problems 1b, 1c, 3)**

*   **Core Principle:** Used when dealing with a fixed number ($N$) of independent trials, each having two possible outcomes ("success" or "failure") with a constant probability of success ($p$). The probability of getting exactly $n$ successes is given by:
    $$ P_N(n) = \binom{N}{n} p^n (1-p)^{N-n} = \frac{N!}{n!(N-n)!} p^n q^{N-n} $$
*   **Key Properties:** Mean number of successes $\bar{n} = Np$, Variance $\sigma_n^2 = Npq$.

*   **Problem 1b (Decimal Digits):**
    *   *Identification:* $N=10$ trials (digits). Success = digit < 5. $p=5/10 = 1/2$. Find $P_{10}(5)$.
    *   *Application:* Direct use of the binomial formula.

*   **Problem 1c (Drunk's Walk - Return):**
    *   *Identification:* $N$ trials (steps). Success = step right ($p=1/2$). Return to origin ($m=0$) means $n_1 = n_2 = N/2$. This requires $N$ to be even. Find $P_N(n_1=N/2)$.
    *   *Application:* Direct use of the binomial formula with $n=N/2$ and $p=1/2$. If $N$ is odd, the probability is 0.

*   **Problem 3 (Molecules in Subvolume):**
    *   *Identification:* $N_0$ trials (molecules). Success = molecule in subvolume $V$. $p = V/V_0$. Find mean $\bar{N}$ and relative dispersion $\sigma_N^2 / \bar{N}^2$.
    *   *Application:* Use properties of the binomial distribution: $\bar{N} = N_0 p$ and $\sigma_N^2 = N_0 p (1-p)$. Calculate relative dispersion using these. Analyze limits $p \to 0$ and $p \to 1$.

### **3. Random Walks & Averages (Problem 1c, Problem 2)**

*   **Core Principle:** Analyzing the net displacement resulting from a sum of independent random steps. Calculating averages, particularly mean square displacement.

*   **Problem 1c (Drunk's Walk):** See Binomial Distribution above. The condition $m=0$ is specific to the random walk context.

*   **Problem 2 (2D Random Walk):**
    *   *Identification:* Sum of $N$ random 2D vectors $\vec{s}_n$ of fixed length $l$ and random direction. Need $\overline{R^2}$ where $\vec{R} = \sum \vec{s}_n$.
    *   *Method:*
        1.  Expand $\overline{R^2} = \overline{(\sum \vec{s}_n) \cdot (\sum \vec{s}_m)} = \sum_n \overline{|\vec{s}_n|^2} + \sum_{n \neq m} \overline{\vec{s}_n \cdot \vec{s}_m}$.
        2.  $\overline{|\vec{s}_n|^2} = l^2$. First term is $Nl^2$.
        3.  Use independence: $\overline{\vec{s}_n \cdot \vec{s}_m} = \overline{\vec{s}_n} \cdot \overline{\vec{s}_m}$ for $n \neq m$.
        4.  Calculate average step: $\overline{\vec{s}_n} = \vec{0}$ because $\overline{\cos\theta}=0$ and $\overline{\sin\theta}=0$ for uniform random angle.
        5.  Cross terms vanish: $\sum_{n \neq m} \overline{\vec{s}_n} \cdot \overline{\vec{s}_m} = 0$.
        6.  Result: $\overline{R^2} = Nl^2$.
    *   *Key Idea:* The mean *square* displacement grows linearly with $N$, even though the mean *displacement* is zero. The vanishing of cross-term averages due to independence is crucial.

### **4. Poisson Distribution (Problem 4)**

*   **Core Principle:** The Poisson distribution $P(n) = \lambda^n e^{-\lambda} / n!$ is the limiting case of the binomial distribution when the number of trials $N$ is very large, the probability of success $p$ is very small, and the mean $\lambda = Np$ is finite and not necessarily large.
*   **Method:**
    1.  Start with the binomial formula.
    2.  Use approximations for the limit $N \gg 1$, $p \ll 1$, $n \ll N$:
        *   $(1-p)^{N-n} \approx (1-p)^N \approx e^{-Np} = e^{-\lambda}$ (using $\ln(1-p)\approx -p$).
        *   $N!/(N-n)! = N(N-1)...(N-n+1) \approx N^n$.
    3.  Substitute these into the binomial formula to get the Poisson formula.
    4.  Verify normalization using the Taylor series for $e^\lambda$.
    5.  Calculate mean and variance (both equal $\lambda$) using summation techniques.

### **5. Continuous Distributions & Transformations (Problem 5)**

*   **Core Principle:** If a random variable $Y$ is a function of a random variable $X$, $Y=f(X)$, their probability densities are related by conserving probability: $P_Y(y)|dy| = \sum_i P_X(x_i)|dx_i|$, where the sum is over all $x_i$ such that $f(x_i)=y$. This gives the transformation rule:
    $$ P_Y(y) = \sum_i P_X(x_i) \left| \frac{dx}{dy} \right|_{x=x_i} $$
*   **Method:**
    1.  Identify the initial random variable (here, $\theta$ or $x=\cos\theta$) and its distribution ($w(\theta)=\frac{1}{2}\sin\theta$ or $P(x)=1/2$).
    2.  Identify the function relating the new variable to the old one ($b = f(\theta)$ or $b = g(x)$).
    3.  Calculate the derivative $dx/db$ (or $d\theta/db$).
    4.  Invert the function to express the old variable in terms of the new one ($x(b)$ or $\theta(b)$). Handle multiple branches (e.g., $\pm$ square roots) if they exist.
    5.  Substitute into the transformation formula. Sum contributions from different branches if necessary.
    6.  For combined probabilities (part b), use $P_{total}(b) = \sum_k P(\text{case } k) P(b | \text{case } k)$. Here, $P(\text{spin up})=P(\text{spin down})=1/2$.

By recognizing which core principle applies, you can approach similar problems more systematically during your review.


---


# **Phase 2: Thermal Interaction, Entropy, and Temperature**

This section builds upon the statistical description to analyze how macroscopic systems interact and exchange energy, leading to the fundamental concepts of entropy and temperature.

## **1. Interaction Between Macroscopic Bodies (Lecture 5)**

### **1.1 Macrostates and External Parameters**

*   The Hamiltonian $H(q, p; x_1, ..., x_n)$ of a system can depend on macroscopic **external parameters** $x_k$ (e.g., volume $V$, applied magnetic field $\vec{B}$).
*   The energy levels $E_r$ of the system depend on these parameters: $E_r = E_r(x_1, ..., x_n)$.
*   A **macrostate** is defined by specifying these external parameters $(x_1, ..., x_n)$ and the total energy $E$ (usually within $[E, E+\delta E]$).

### **1.2 Types of Interactions Between Systems A and B**

Consider two systems A and B combined into a total system A+B. The total energy is $E_{total} = E_A + E_B$.

*   **Thermal Interaction:**
    *   Systems can exchange energy without changes in external parameters (e.g., volumes $V_A, V_B$ are fixed).
    *   Energy levels $E_r^{(A)}$, $E_r^{(B)}$ remain fixed.
    *   Energy is exchanged, leading to changes in the energies $E_A$ and $E_B$ of the individual systems, subject to $E_A + E_B = E_{total} = \text{const}$.
    *   The exchanged energy is defined as **heat** $Q$. If system A absorbs energy $\Delta E_A$, then $Q_A = \Delta E_A$.

*   **Mechanical Interaction (Adiabatic):**
    *   Systems are thermally isolated (no heat exchange, $Q=0$).
    *   Energy is exchanged via changes in external parameters (e.g., volume change due to piston movement).
    *   Energy levels $E_r(x)$ change as parameters $x$ change.
    *   The energy exchanged due to changes in external parameters is defined as **work** $W$.

*   **General Interaction:** Both heat and work exchanges can occur simultaneously.

## **2. Quasi-static Processes, Work, Heat, and First Law (Lecture 6)**

### **2.1 Quasi-static Processes**

*   A process carried out sufficiently slowly such that the system remains arbitrarily close to equilibrium at all intermediate stages.
*   This implies the process occurs on timescales $t$ much larger than the system's internal relaxation time $\tau$ ($t \gg \tau$).
*   During a quasi-static process, thermodynamic variables like pressure $p$ and temperature $T$ are well-defined throughout the system.

### **2.2 Work and Heat in Statistical Terms**

*   Consider a quasi-static process where an external parameter $x$ changes by $dx$. The Hamiltonian $H(q,p; x)$ changes.
*   The change in energy of a single microstate is $dE_r = (\partial E_r / \partial x) dx$.
*   The average energy change of the system is $dE = \overline{dE_r}$.
*   **Work:** The change in the average energy due to the change in the energy levels themselves (driven by $dx$).
    *   Work done *on* the system: $W_{on} = \sum_r P_r dE_r = \overline{(\partial H/\partial x)} dx$. (Note: $P_r$ is the probability of being in state r).
    *   Define **generalized force** conjugate to $x$: $X = -\overline{(\partial H/\partial x)}$.
    *   Work done *by* the system: $$ W = -W_{on} = X dx $$
    *   Example: $x=V$. $X = p$. $W = p dV$.
*   **Heat:** The change in the average energy due to the change in the *probabilities* $P_r$ (or occupation of energy levels) at fixed external parameters.
    *   $dE = \sum_r (E_r dP_r + P_r dE_r) = Q + W_{on}$.
    *   Heat absorbed by the system: $$ Q = \sum_r E_r dP_r = dE - W_{on} = dE + W $$

### **2.3 First Law of Thermodynamics**

*   The change in the average internal energy $dE$ of a system is equal to the heat $Q$ absorbed by the system minus the work $W$ done by the system.
    $$
    \boxed{ dE = Q - W }
    $$ or equivalently, $Q = dE + W$.
*   This is a statement of energy conservation for thermodynamic systems.

### **2.4 Exact and Inexact Differentials**

*   $dE$ is an **exact differential**. The change in internal energy $\Delta E = E_f - E_i$ depends only on the initial and final states, not on the path taken. $E$ is a **state function**.
*   $W$ and $Q$ are **inexact differentials** (often written as $\delta W$ or $đW$, $\delta Q$ or $đQ$). The total work $W_{if} = \int_i^f W$ and total heat $Q_{if} = \int_i^f Q$ depend on the specific process (path) connecting the initial state $i$ and final state $f$. Work and Heat are *not* state functions; they represent energy *in transit*.

## **3. Thermal Interaction, Entropy, and Temperature (Lecture 7)**

### **3.1 Thermal Equilibrium**

*   Consider two systems A1 and A2, isolated from the outside but allowed to exchange energy (thermal contact). Fixed volumes $V_1, V_2$. Total energy $E = E_1 + E_2$ is constant.
*   The number of accessible microstates for the combined system when system 1 has energy $E_1$ (and system 2 has $E_2 = E-E_1$) is $\Omega_{total}(E_1) = \Omega_1(E_1) \Omega_2(E-E_1)$.
*   The probability of finding system 1 with energy $E_1$ is $P(E_1) = \Omega_{total}(E_1) / \sum_{E_1'} \Omega_{total}(E_1')$.
*   **Equilibrium Condition:** The most probable state corresponds to the maximum value of $\Omega_{total}(E_1)$. This occurs when $\partial \Omega_{total} / \partial E_1 = 0$.

### **3.2 Entropy Definition**

*   The **statistical entropy** $S$ of a system in a macrostate characterized by $E, V, N$ is defined as the logarithm of the number of accessible microstates:
    $$
    \boxed{ S(E, V, N) \equiv \ln \Omega(E, V, N) }
    $$ (We use $k_B=1$, so $S$ has units of energy/temperature, which is dimensionless here, or energy units if T is in energy units).
*   Entropy is a **state function**.
*   Maximizing $\Omega_{total}$ is equivalent to maximizing $\ln \Omega_{total} = \ln \Omega_1 + \ln \Omega_2 = S_1 + S_2$.
*   Equilibrium condition (thermal): $\frac{\partial S_{total}}{\partial E_1} = \frac{\partial S_1}{\partial E_1} + \frac{\partial S_2}{\partial E_1} = \frac{\partial S_1}{\partial E_1} + \frac{\partial S_2}{\partial E_2}\frac{dE_2}{dE_1} = \frac{\partial S_1}{\partial E_1} - \frac{\partial S_2}{\partial E_2} = 0$.

### **3.3 Temperature Definition**

*   The **absolute temperature** $T$ is defined via the change in entropy with energy at constant external parameters (like $V, N$):
    $$
    \boxed{ \frac{1}{T} \equiv \left( \frac{\partial S}{\partial E} \right)_{V, N} }
    $$
*   Temperature is a measure of the sensitivity of the number of accessible states (or entropy) to changes in energy.
*   Units: With $k_B=1$, $T$ has units of energy. $S$ is dimensionless. If $S$ is defined as $k_B \ln \Omega$, then $T$ is the conventional temperature (Kelvin) and $S$ has units of $k_B$ (J/K).

### **3.4 Thermal Equilibrium Condition Revisited**

*   The equilibrium condition $\frac{\partial S_1}{\partial E_1} = \frac{\partial S_2}{\partial E_2}$ becomes:
    $$ \frac{1}{T_1} = \frac{1}{T_2} \quad \implies \quad T_1 = T_2 $$
*   Two systems in thermal contact are in equilibrium when their temperatures are equal.

### **3.5 Properties of Temperature**

*   Since $\Omega(E)$ typically increases rapidly with $E$ (like $E^{fN/2}$), $S = \ln \Omega$ also increases with $E$. Therefore $(\partial S / \partial E) > 0$, which means $T > 0$.
*   Energy flows from higher $T$ to lower $T$. If $T_1 > T_2$, then $1/T_1 < 1/T_2$. If system 1 transfers energy $dE_1 < 0$ (so $dE_2 > 0$), the total entropy change is $dS = dS_1 + dS_2 = (1/T_1)dE_1 + (1/T_2)dE_2 = (-1/T_1 + 1/T_2)|dE_1| > 0$. The total entropy increases when heat flows from hot to cold.

## **4. Entropy and Probability Distribution Sharpness (Lecture 8)**

### **4.1 Additivity of Entropy**

*   For the combined system in thermal equilibrium, the total number of states was $\Omega_{total} \approx \Omega_1(\tilde{E}_1) \Omega_2(\tilde{E}_2) \times (\text{width factor})$.
*   Taking the logarithm: $S_{total} = \ln \Omega_{total} \approx \ln \Omega_1(\tilde{E}_1) + \ln \Omega_2(\tilde{E}_2) + \ln(\text{width})$.
*   $S_{total} \approx S_1(\tilde{E}_1) + S_2(\tilde{E}_2)$.
*   The entropy of the combined system (at equilibrium) is the sum of the entropies of the individual systems evaluated at their most probable energies. Entropy is **additive** for systems in equilibrium.

### **4.2 Sharpness of the Energy Distribution**

*   Consider the probability $P(E_1) \propto \Omega_1(E_1)\Omega_2(E-E_1)$. Its logarithm is $\ln P(E_1) = S_1(E_1) + S_2(E-E_1) + \text{const}$.
*   Let $E_1 = \tilde{E}_1 + \eta$, where $\tilde{E}_1$ is the most probable energy (equilibrium) and $\eta$ is a small deviation.
*   Taylor expand $S_1$ and $S_2$ around $\tilde{E}_1$ and $\tilde{E}_2 = E - \tilde{E}_1$:
    *   $S_1(E_1) \approx S_1(\tilde{E}_1) + \frac{\partial S_1}{\partial E_1}|_{\tilde{E}_1} \eta + \frac{1}{2} \frac{\partial^2 S_1}{\partial E_1^2}|_{\tilde{E}_1} \eta^2$
    *   $S_2(E-E_1) = S_2(\tilde{E}_2-\eta) \approx S_2(\tilde{E}_2) - \frac{\partial S_2}{\partial E_2}|_{\tilde{E}_2} \eta + \frac{1}{2} \frac{\partial^2 S_2}{\partial E_2^2}|_{\tilde{E}_2} (-\eta)^2$
*   At equilibrium $\frac{\partial S_1}{\partial E_1} = \frac{\partial S_2}{\partial E_2} = \frac{1}{T}$. The linear terms in $\eta$ cancel.
*   $\ln P(E_1) \approx \ln P(\tilde{E}_1) + \frac{1}{2} \left( \frac{\partial^2 S_1}{\partial E_1^2} + \frac{\partial^2 S_2}{\partial E_2^2} \right) \eta^2$.
*   Define $\lambda_i = -\frac{\partial^2 S_i}{\partial E_i^2} = -\frac{\partial (1/T_i)}{\partial E_i}$. Since $T$ increases with $E$, $1/T$ decreases, so $\lambda_i > 0$.
*   $\ln P(E_1) \approx \ln P(\tilde{E}_1) - \frac{1}{2}(\lambda_1 + \lambda_2) \eta^2$.
*   This shows $P(E_1)$ is a Gaussian distribution around $\tilde{E}_1$:
    $$ P(E_1) \approx P(\tilde{E}_1) e^{-\frac{(\lambda_1+\lambda_2)}{2}(E_1-\tilde{E}_1)^2} $$
*   The variance $\sigma_{E_1}^2 = 1/(\lambda_1 + \lambda_2)$.
*   Since $S \propto N$ and $E \propto N$, the derivatives scale as: $\frac{\partial S}{\partial E} \sim \frac{N}{N} \sim 1$, and $\frac{\partial^2 S}{\partial E^2} = \frac{\partial (1/T)}{\partial E} \sim \frac{1}{N}$.
*   So, $\lambda \propto 1/N$. The variance $\sigma_{E_1}^2 \propto N$.
*   The standard deviation $\Delta^* E_1 = \sigma_{E_1} \propto \sqrt{N}$.
*   The relative width:
    $$
    \boxed{ \frac{\Delta^* E_1}{\tilde{E}_1} \propto \frac{\sqrt{N}}{N} = \frac{1}{\sqrt{N}} }
    $$
*   **Conclusion:** For macroscopic systems ($N \sim 10^{23}$), the probability distribution for energy sharing is extremely sharp. Fluctuations around the equilibrium state are negligible.

----


## **Homework 2 & 3 Core Principles Review**

### **1. Phase Space, Microstates $\Omega(E)$, and Density of States $\omega(E)$**

*   **Core Principle:** The state of a classical system is a point in phase space. For an isolated system with energy in $[E, E+\delta E]$, the number of accessible microstates is $\Omega(E)$. This is proportional to the accessible volume in phase space. $\Omega(E) = \omega(E)\delta E$, where $\omega(E)$ is the density of states.
*   **Relevant Problems:**
    *   **HW2 Prob 1b (Oscillator Phase Space):** Calculates probability $p(x)dx$ by finding the ratio of phase space volume where the oscillator is between $x$ and $x+dx$ (within the energy shell $E$ to $E+\delta E$) to the total phase space volume in that energy shell. This directly uses the concept of accessible states and their volume in phase space. The calculation involves finding the area $dA$ corresponding to $dx$ within the energy shell area $A$.
    *   **HW2 Prob 2 (Ideal Gas DOS):** Explicitly calculates the phase space volume $\Omega(E)$ for an ideal gas in $D$ dimensions. Integrates over coordinates ($V^{N}$) and finds the volume of a $ND$-dimensional hypersphere shell in momentum space. Derives $\omega(E) = d\Phi/dE \propto V^{ND} E^{ND/2 - 1}$. This is a direct application of calculating $\Omega$ and $\omega$.
    *   **HW2 Prob 3 (N Oscillators DOS):** Simplifies the Hamiltonian using a canonical transformation and then applies the same logic as Prob 2 (volume of a $2N$-dimensional hypersphere shell) to find $\Omega(E) \propto E^N$. Another direct calculation of $\Omega$ and $\omega$.
    *   **HW2 Prob 4a (Spins $\Omega(E)$):** Calculates $\Omega(E)$ by *counting* discrete microstates (spin configurations) $\binom{N}{n_1}$ corresponding to energy $E = -(n_1-n_2)\mu H$. It approximates the number of states in $[E, E+\delta E]$ by $\binom{N}{n_1} \times \delta n$, where $\delta n = \delta E / (2\mu H)$ is the number of spin flips needed to cover the energy range $\delta E$. This connects the discrete counting approach to $\Omega(E)$. It then defines $\omega(E) = \Omega(E)/\delta E$.

### **2. Entropy $S = \ln \Omega$ and Temperature $1/T = (\partial S / \partial E)$**

*   **Core Principle:** Entropy is the logarithm of the number of accessible microstates. Temperature is defined via the partial derivative of entropy with respect to energy.
*   **Relevant Problems:**
    *   **HW2 Prob 4b (Spins Entropy):** Calculates $S = \ln \Omega(E)$ using the result from 4a and applies Stirling's approximation to simplify.
    *   **HW3 Prob 1a (Spin Temperature):** Calculates $1/T = \partial S / \partial E$ using the entropy $S(E)$ derived in HW2 P4b. Inverts the relation to find $E(T)$. This directly applies the statistical definition of temperature.
    *   **HW3 Prob 1b (Negative Temperature):** Sketches $S(E)$ and $T(E)$ for the spin system, showing that $S(E)$ is non-monotonic (has a maximum) leading to the possibility of $T<0$ when $\partial S / \partial E < 0$.
    *   **HW3 Prob 3b (Ideal Gas Mixture Pressure):** Calculates $S = \ln \Omega$. Uses the (implicitly derived) thermodynamic relation $p/T = (\partial S / \partial V)_E$ to find the pressure $p$. This connects entropy to the equation of state.

### **3. First Law ($\Delta E = Q - W$) and Work ($\delta W = p dV$)**

*   **Core Principle:** Energy is conserved; changes in internal energy are due to heat transfer or work done. Work is energy transfer via changes in external parameters. For volume changes, $\delta W = p dV$. Heat and Work are path-dependent; Energy is a state function.
*   **Relevant Problems:**
    *   **HW2 Prob 5a (Particle in Box Force):** Relates the work done $dW = F_x dL_x$ during a quasi-static change $dL_x$ to the change in the particle's energy level $dE = -dW$. This establishes $F_x = -\partial E / \partial L_x$. This is a microscopic application of the work-energy relationship (First Law with $Q=0$).
    *   **HW2 Prob 6 (Thermodynamic Processes):** Calculates work $W = \int p dV$ for three different paths between states A and B. Calculates $\Delta E$ using the path where $Q=0$ ($dE=-dW$). Uses $\Delta E = Q-W$ to find heat $Q$ for the other paths, demonstrating path dependence of $Q, W$ and path independence of $\Delta E$.
    *   **HW3 Prob 1c (Heat Flow $T<0$):** Uses $dW=0$ for thermal contact, so $dQ_1 = dE_1$. Determines the sign of $dE_1$ based on the Second Law.
    *   **HW3 Prob 2c (Heat in Spin System):** Calculates heat $Q = \Delta E = E_{final} - E_{initial}$ because work done is zero ($W=0$) for thermal contact between spin systems with fixed $H$.

### **4. Equilibrium and Second Law ($\Delta S_{total} \ge 0$)**

*   **Core Principle:** Isolated systems evolve towards the state of maximum entropy (maximum $\Omega_{total}$). In equilibrium, entropy is maximized, and intensive parameters (like T) are equal between interacting systems.
*   **Relevant Problems:**
    *   **HW3 Prob 1c (Heat Flow $T<0$):** Analyzes $dS_{total} = (1/T_1 - 1/T_2)dE_1$. Applies the Second Law ($dS_{total} \ge 0$) to determine the sign of $dE_1$ (direction of heat flow) when $T_1<0$ and $T_2>0$. Shows heat flows from the negative T system (hotter) to the positive T system (colder).
    *   **HW3 Prob 2a (Spin Equilibrium):** Uses the equilibrium condition $T=T'$, which implies $\partial S_A / \partial E = \partial S_{A'} / \partial E'$, to find the relationship between the final energies $\tilde{E}$ and $\tilde{E}'$.
    *   **HW3 Prob 3c (Gas Permeation):** A conceptual problem relying on reaching equilibrium where the partial pressure of Helium inside the bulb equals the external pressure (implying equality of chemical potentials, though not explicitly calculated).

### **5. Probability Distributions Near Equilibrium (Fluctuations)**

*   **Core Principle:** The probability of observing a fluctuation (e.g., energy $E$ instead of the most probable $\tilde{E}$) is governed by the total number of states $\Omega_{total} \propto e^{S_{total}}$. Near equilibrium (maximum entropy), $S_{total}$ can be approximated by a Gaussian, leading to a Gaussian probability distribution for fluctuations.
*   **Relevant Problems:**
    *   **HW2 Prob 4c (Spins Gaussian Approx):** Approximates $S = \ln \Omega(E)$ for the spin system near $E=0$ using a Taylor expansion, leading to a Gaussian form for $\Omega(E) \approx C e^{-E^2/(2\sigma^2)}$.
    *   **HW3 Prob 2d (Probability P(E)dE):** Explicitly calculates the probability distribution $P(E) \propto \Omega(E)\Omega(E_t-E)$ using the Gaussian approximation for the entropy/density of states from HW2 P4c for both systems. Shows the result is a Gaussian centered at the equilibrium energy $\tilde{E}$.
    *   **HW3 Prob 2e, 2f (Dispersion):** Calculates the variance $\sigma^2$ of the energy distribution $P(E)$ found in 2d, representing the magnitude of thermal fluctuations. Calculates the relative fluctuation $\sigma/\tilde{E}$.

-----



\format

# **Phase 3: Thermodynamic Relations and Ideal Gas (Lectures 9-11)**

This section combines the statistical definitions with the laws of thermodynamics to derive fundamental relations and apply them to the ideal gas model. (Reif 3.2, 3.8-3.12, 4.4, 4.7, 5.1-5.4).

## **1. General Interaction, Equilibrium, Thermodynamic Identity (Lecture 9)**

### **1.1 General Equilibrium Conditions**

*   Consider two systems (1 & 2) that can exchange both energy and volume ($E=E_1+E_2$, $V=V_1+V_2$). The total system is isolated.
*   Equilibrium corresponds to the maximum of the total entropy $S_{total} = S_1(E_1, V_1) + S_2(E_2, V_2)$.
*   Condition $dS_{total} = 0$ for arbitrary variations $dE_1, dV_1$:
    $$ dS_{total} = \left( \frac{\partial S_1}{\partial E_1} - \frac{\partial S_2}{\partial E_2} \right) dE_1 + \left( \frac{\partial S_1}{\partial V_1} - \frac{\partial S_2}{\partial V_2} \right) dV_1 = 0 $$
*   This requires the coefficients of $dE_1$ and $dV_1$ to vanish independently:
    1.  **Thermal Equilibrium:** $\frac{\partial S_1}{\partial E_1} = \frac{\partial S_2}{\partial E_2} \implies \boxed{T_1 = T_2}$
    2.  **Mechanical Equilibrium:** $\frac{\partial S_1}{\partial V_1} = \frac{\partial S_2}{\partial V_2}$

### **1.2 Identifying $(\partial S / \partial V)_E$**

*   Consider a quasi-static, adiabatic ($Q=0$) process.
*   First Law: $dE = Q - W = 0 - p dV = -p dV$.
*   Entropy is constant ($S(E,V)$): $dS = (\partial S/\partial E)_V dE + (\partial S/\partial V)_E dV = 0$.
*   Substitute $dE = -p dV$ and $(\partial S/\partial E)_V = 1/T$:
    $$ \frac{1}{T}(-p dV) + \left(\frac{\partial S}{\partial V}\right)_E dV = 0 $$
    $$ \implies \boxed{ \left(\frac{\partial S}{\partial V}\right)_E = \frac{p}{T} } $$
*   The mechanical equilibrium condition $(\partial S_1/\partial V_1) = (\partial S_2/\partial V_2)$ becomes $p_1/T_1 = p_2/T_2$. Combined with $T_1=T_2$, this yields:
    $$ \boxed{ p_1 = p_2 } $$
    Equilibrium requires equal temperatures and equal pressures.

### **1.3 Thermodynamic Identity**

*   Start with the total differential for entropy $S(E, V)$:
    $$ dS = \left(\frac{\partial S}{\partial E}\right)_V dE + \left(\frac{\partial S}{\partial V}\right)_E dV $$
*   Substitute the definitions $1/T = (\partial S/\partial E)_V$ and $p/T = (\partial S/\partial V)_E$:
    $$ dS = \frac{1}{T} dE + \frac{p}{T} dV $$
*   Rearranging gives the fundamental **Thermodynamic Identity**:
    $$
    \boxed{ dE = T dS - p dV }
    $$
*   This equation relates changes in state functions ($E, S, V$) for an infinitesimal process between equilibrium states. It holds for *any* such process, not just quasi-static ones (though $T dS$ and $p dV$ only equal heat and work for quasi-static processes).
*   If particle number $N$ can change, the identity becomes:
    $$ dE = T dS - p dV + \mu dN $$

### **1.4 Relation $T dS = Q$ for Quasi-static Processes**

*   First Law: $dE = Q - W$.
*   For a quasi-static process: $W = p dV$.
*   Substituting into First Law: $dE = Q - p dV$.
*   Comparing with the thermodynamic identity $dE = T dS - p dV$:
    $$ \implies Q = T dS \quad \text{(quasi-static process)} $$
*   This provides a thermodynamic definition of entropy change: $dS = Q_{rev} / T$, where $Q_{rev}$ is the heat absorbed in a reversible (quasi-static) process.
*   Since $S$ is a state function, $\Delta S = S_f - S_i = \int_i^f Q_{rev} / T$ is independent of the reversible path chosen.

## **2. Recap of Laws, Heat Capacity, Extensive/Intensive (Lecture 10)**

### **2.1 Laws of Thermodynamics (Statistical Basis)**

*   **Zeroth Law:** If A equilibrium C, B equilibrium C $\implies$ A equilibrium B. (Follows from $T_A=T_C, T_B=T_C \implies T_A=T_B$).
*   **First Law:** $E$ is a state function, $\Delta E = Q - W$. (Energy conservation).
*   **Second Law:** $S=\ln \Omega$ is a state function. For isolated systems, $\Delta S \ge 0$. For quasi-static processes, $dS = Q/T$. (Follows from maximizing $\Omega$).
*   **Third Law:** As $T \to 0$, $S \to S_0$ (a constant, often 0). (Follows from quantum ground states).

### **2.2 Heat Capacities**

*   Measure of how much heat is needed to change temperature. $Q = C_x dT$ for process at constant $x$.
*   **Constant Volume:** $C_V = \left(\frac{Q}{dT}\right)_V$. Since $W=0$ at constant $V$, $Q_V = dE_V$.
    $$
    \boxed{ C_V = \left(\frac{\partial E}{\partial T}\right)_V }
    $$
*   **Constant Pressure:** $C_p = \left(\frac{Q}{dT}\right)_p$. $Q_p = dE_p + W_p = dE_p + p dV_p$.
    $$
    \boxed{ C_p = \left(\frac{\partial E}{\partial T}\right)_p + p \left(\frac{\partial V}{\partial T}\right)_p }
    $$
    (Alternatively, using Enthalpy $H=E+pV$, $dH = dE+pdV+Vdp$. $Q_p = dH_p$. So $C_p = (\partial H/\partial T)_p$).
*   Relation to Entropy: Since $Q = T dS$ (quasi-static):
    $$ C_x = T \left(\frac{\partial S}{\partial T}\right)_x $$

### **2.3 Extensive and Intensive Quantities**

*   **Extensive:** Proportional to system size/amount of substance (e.g., $E, V, S, N, C_V, C_p$). Additive for combined systems.
*   **Intensive:** Independent of system size (e.g., $T, p, \mu$, density $n=N/V$, molar specific heat $c_v=C_V/N$). Not additive.

## **3. Applications to Ideal Gas (Lecture 11)**

### **3.1 Ideal Gas Properties**

*   Equation of State: $p V = N T$ (using $k_B=1$, $T$ in energy units).
*   Microscopic derivation (classical, monatomic): $E = \frac{3}{2} N T$.

### **3.2 $E$ depends only on $T$ for Ideal Gas (Macroscopic Derivation)**

*   Goal: Show $(\partial E / \partial V)_T = 0$ using only $p V = N T$ and general thermodynamic relations.
*   Started with $dE = (\partial E / \partial T)_V dT + (\partial E / \partial V)_T dV$ and $d S = (1/T)(\partial E / \partial T)_V dT + (1/T)[(\partial E / \partial V)_T + p] dV$.
*   Used equality of mixed partials $\partial^2 S / (\partial V \partial T) = \partial^2 S / (\partial T \partial V)$.
*   Derived the general relation:
    $$ \left(\frac{\partial E}{\partial V}\right)_T = T \left(\frac{\partial p}{\partial T}\right)_V - p $$
*   For ideal gas $p=NT/V$, so $(\partial p / \partial T)_V = N/V$.
*   $(\partial E / \partial V)_T = T(N/V) - p = p - p = 0$.
*   Conclusion: For any gas obeying $pV=NT$, the internal energy $E$ must be a function of $T$ only, $E=E(T)$.

### **3.3 Heat Capacities of Ideal Gas**

*   $C_V = (\partial E / \partial T)_V$. Since $E=E(T)$, $C_V = dE/dT$. Also depends only on $T$. $dE = C_V(T) dT$.
*   $C_p = (\partial E / \partial T)_p + p (\partial V / \partial T)_p$. Since $E=E(T)$, $(\partial E / \partial T)_p = dE/dT = C_V$. From $V=NT/p$, $(\partial V / \partial T)_p = N/p$.
*   $C_p = C_V + p(N/p) = C_V + N$.
    $$
    \boxed{ C_p - C_V = N } \quad \text{(Ideal Gas, } k_B=1 \text{)}
    $$
    (Or $c_p - c_v = R$ in molar units with $T$ in Kelvin). $C_p > C_V$ because at constant pressure, heat goes into both increasing $E$ and doing work $p dV$.

### **3.4 Adiabatic Process for Ideal Gas ($Q=0$)**

*   Goal: Find relation between $p, V$ during a quasi-static adiabatic process.
*   First Law: $Q=0 \implies dE + W = 0 \implies C_V dT + p dV = 0$.
*   Use ideal gas law $p V = N T$. Differentiate: $p dV + V dp = N dT$.
*   Eliminate $dT$: $C_V (\frac{p dV + V dp}{N}) + p dV = 0$.
*   Multiply by $N$: $C_V(p dV + V dp) + N p dV = 0$.
*   $(C_V + N) p dV + C_V V dp = 0$.
*   Use $C_p = C_V + N$: $C_p p dV + C_V V dp = 0$.
*   Divide by $p V C_V$: $(C_p/C_V) (dV/V) + (dp/p) = 0$.
*   Define adiabatic index $\gamma = C_p / C_V$.
    $$ \gamma \frac{dV}{V} + \frac{dp}{p} = 0 $$
*   Integrate (assuming $\gamma$ constant): $\gamma \ln V + \ln p = \text{const}$.
    $$
    \boxed{ p V^\gamma = \text{constant} } \quad \text{(Adiabatic process, Ideal Gas)}
    $$
*   Can also write $T V^{\gamma-1} = \text{constant}$.
*   Since $\gamma > 1$, pressure falls more steeply with volume in an adiabatic expansion ($p \propto V^{-\gamma}$) than in an isothermal one ($p \propto V^{-1}$).

This covers Phase 3, bridging statistical definitions with macroscopic thermodynamic laws and applying them to the ideal gas. 

----
Okay, let's review Homework 4, which covers material from the end of Phase 2 and into Phase 3, focusing on the application of thermodynamics, particularly to ideal gases and processes.

\format

## **Homework 4 Core Principles Review**

### **1. General Thermodynamic Relations and Equations of State (Problem 1)**

*   **Core Principle:** The relationship between $p, V, T$ (equation of state) and the internal energy $E$ are linked by fundamental thermodynamic relations derived from the exactness of state function differentials (like $dS$ or $dF$). Specifically, the problem uses the relation derived in Lecture 11:
    $$ \left(\frac{\partial E}{\partial V}\right)_T = T \left(\frac{\partial p}{\partial T}\right)_V - p $$
*   **Method:**
    1.  Start with the given general relation above.
    2.  Apply the constraint that $E$ depends only on $T$, i.e., $E=E(T)$, which implies $(\partial E / \partial V)_T = 0$.
    3.  This simplifies the general relation to $T (\partial p / \partial T)_V = p$.
    4.  Recognize this as a separable partial differential equation for $p(T, V)$. Treat $V$ as constant during the integration with respect to $T$.
    5.  Solve the ODE: $\frac{dp}{p} = \frac{dT}{T} \implies \ln p = \ln T + \text{const}(V)$.
    6.  Exponentiate: $p = e^{\text{const}(V)} T$. Let $f(V) = e^{\text{const}(V)}$.
    7.  Result: The most general equation of state is $p(T, V) = f(V) T$.
*   **Connection to Phase 3:** Tests understanding of the general relation derived from Maxwell relations/exact differentials and its application to constrain the equation of state given information about the energy function.

### **2. Entropy of Mixing and Gibbs Paradox (Problem 2)**

*   **Core Principle:** Entropy is additive for distinct systems ($S_{total} = S_1 + S_2$). For an ideal gas, the entropy depends on $V, N, E$ (or $T$). When identical gases mix at the same temperature and pressure, there should be no change in entropy because the initial and final macroscopic states are indistinguishable. The naive classical calculation using $S \propto N \ln V + \frac{3}{2}N \ln E$ leads to $\Delta S > 0$, the Gibbs Paradox. The resolution requires accounting for particle indistinguishability (the $1/N!$ factor in $Z$).
*   **Method:**
    1.  Write the initial entropy $S_i$ using the naive formula $S=N\ln V + \frac{3}{2}N\ln E$ for each gas, assuming they are distinguishable.
    2.  Write the final entropy $S_f$ for the combined system $(2N, V_1+V_2, E_1+E_2)$.
    3.  Calculate $\Delta S = S_f - S_i$.
    4.  Use $pV=NT$ and $E=\frac{3}{2}NT$ to express $V$ and $E$ terms in terms of $T_1, T_2$.
    5.  Show that even if $T_1=T_2$, $\Delta S > 0$ (specifically $5N \ln 2$ in the solution's algebra, though the usual result for mixing at constant T, p is $N \ln 2$ per component - check the algebra/setup).
    6.  State the resolution: The formula for $\Omega$ (and thus $S$) must include the $1/N!$ factor for identical particles. This modifies the entropy to $S \propto N \ln(V/N) + ...$, making it properly extensive and resolving the paradox ($\Delta S = 0$ for mixing identical gases at same T, p).
*   **Connection to Phase 2/3:** This problem directly addresses the additivity and extensivity of entropy, a key concept from Phase 2, and its implications, connecting to the need for the quantum correction ($1/N!$) discussed at the start of Phase 6 but motivated here.

### **3. Adiabatic Processes for Ideal Gas (Problem 3)**

*   **Core Principle:** An adiabatic process is one with no heat exchange ($Q=0$). A quasi-static adiabatic process is also reversible ($dS=0$). For an ideal gas undergoing such a process, $p V^\gamma = \text{constant}$, where $\gamma = C_p/C_v$.
*   **Method (Part a):**
    1.  Start with $p V^\gamma = \text{const}$.
    2.  Use the ideal gas law $p = NT/V$ to eliminate $p$: $(NT/V)V^\gamma = \text{const} \implies T V^{\gamma-1} = \text{const}'$.
    3.  Apply this between initial $(T_i, V_i)$ and final $(T_f, V_f)$ states: $T_f V_f^{\gamma-1} = T_i V_i^{\gamma-1}$.
    4.  Solve for $T_f$.
    5.  Substitute the value of $\gamma$ for a monatomic ideal gas ($\gamma = 5/3 \implies \gamma-1 = 2/3$).
*   **Method (Part b):**
    1.  Start with $dS=0$ for a reversible adiabatic process.
    2.  Use the thermodynamic identity $dE = TdS - pdV$. Since $dS=0$, $dE = -pdV$.
    3.  For an ideal gas, $dE = C_V dT$. Substitute: $C_V dT = -p dV$.
    4.  Use $p=NT/V$: $C_V dT = -(NT/V) dV$.
    5.  Separate variables: $(C_V/N) (dT/T) = -(dV/V)$. (Note $C_V/N = c_v$).
    6.  Integrate from $(T_i, V_i)$ to $(T_f, V_f)$: $c_v \ln(T_f/T_i) = - \ln(V_f/V_i) = \ln(V_i/V_f)$.
    7.  Solve for $T_f$: $T_f = T_i (V_i/V_f)^{1/c_v}$. (Using $k_B=1$, $c_v$ is per particle). If using molar $c_v$, $T_f = T_i (V_i/V_f)^{R/c_v}$.
    8.  Recall $R = c_p - c_v \implies R/c_v = c_p/c_v - 1 = \gamma - 1$.
    9.  Result: $T_f = T_i (V_i/V_f)^{\gamma-1}$, matching part (a).
*   **Connection to Phase 3:** Direct application of the First Law ($dE=-pdV$) and the relation $p V^\gamma = \text{const}$ for adiabatic processes in an ideal gas. Part (b) also uses the entropy formulation $dS=0$.

### **4. Cyclic Processes, Work, Heat (Problems 4, 5)**

*   **Core Principle:** For a cyclic process, the system returns to its initial state, so the change in any state function (like internal energy $E$) is zero: $\Delta E_{cycle} = 0$.
*   **First Law for cycle:** $\Delta E_{cycle} = Q_{net} - W_{net} = 0 \implies Q_{net} = W_{net}$.
*   **Work:** The net work done $W_{net}$ in a cycle is the area enclosed by the cycle path on a $p-V$ diagram (positive if clockwise, negative if counterclockwise).
*   **Heat:** Heat absorbed/rejected during specific parts of the cycle can be calculated using $Q = \Delta E + W$ for that part.
*   **Relevant Problems:**
    *   **HW4 Prob 4:**
        *   a) $W_{net}$ = Area of circle = $\pi r^2$ (using appropriate units for $p, V$ axes).
        *   b) $\Delta E_{A \to C} = E_C - E_A$. For ideal gas $E=\frac{3}{2}NT = \frac{3}{2}pV$. $\Delta E_{AC} = \frac{3}{2}(p_C V_C - p_A V_A)$.
        *   c) Heat $Q_{ABC} = \Delta E_{AC} + W_{ABC}$. $W_{ABC}$ is the area under the path ABC.
    *   **HW4 Prob 5:** Calculates net work and heat for various cycles composed of isobaric, isochoric, isothermal, and adiabatic steps.
        *   Work in each step: Isobaric ($p\Delta V$), Isochoric (0), Isothermal ($NT \ln(V_f/V_i)$), Adiabatic ($-\Delta E = -C_V \Delta T$).
        *   Net work is the sum of work in each step.
        *   Heat in each step: Use $Q = \Delta E + W$. For ideal gas, $\Delta E = C_V \Delta T$. Isochoric: $Q = C_V \Delta T$. Isobaric: $Q = C_p \Delta T$. Isothermal: $Q=W$. Adiabatic: $Q=0$.
*   **Connection to Phase 3:** Application of First Law, calculation of work for different processes, understanding state functions ($\Delta E=0$ for cycle).

### **5. Adiabatic Processes in Atmosphere (Problem 6)**

*   **Core Principle:** Combining hydrostatic equilibrium with the equation of state and adiabatic process relations.
*   **Method:**
    *   a) Hydrostatic equilibrium: Force balance $p(z)A - p(z+dz)A - dm\, g = 0$. Use $dm = \rho V = (\mu/V_{molar}) (A dz)$ and ideal gas law $pV_{molar}=RT$ to relate density and pressure/temperature, leading to $dp/p = -(\mu g/RT)dz$.
    *   b) Adiabatic relation: $p^{1-\gamma} T^\gamma = C$. Differentiate logarithmically: $(1-\gamma)dp/p + \gamma dT/T = 0 \implies dp/p = [\gamma/(\gamma-1)] dT/T$.
    *   c) Combine (a) and (b) to find $dT/dz = -(\mu g/R) (\gamma-1)/\gamma$, the adiabatic lapse rate.
    *   d) Isothermal atmosphere: Integrate $dp/p = -(\mu g/RT)dz$ assuming $T$ is constant.
    *   e) Adiabatic atmosphere: Integrate $dp/p = [\gamma/(\gamma-1)] dT/T$ using $T(z)$ found from integrating $dT/dz$.
*   **Connection to Phase 3:** Application of ideal gas law, adiabatic process relations, and hydrostatic equilibrium.

This homework set heavily reinforces the concepts from Phase 3, especially the First Law, work/heat calculations for various processes (isothermal, adiabatic, isobaric, isochoric), and the properties of ideal gases. It also touches upon concepts from Phase 2 like entropy and equilibrium.


------


# **Phase 4: Thermodynamic Potentials and Applications (Lectures 12-16)**

This section introduces thermodynamic potentials beyond internal energy ($E$) and entropy ($S$) and explores their properties and applications to important thermodynamic processes and cycles. (Reif 5.5, 5.8-5.12, 8.1-8.3).

## **1. Thermodynamic Potentials (Lecture 12)**

Internal energy $E$ is naturally expressed as $E(S, V)$, with $dE = T dS - p dV$. However, $(S, V)$ are often not convenient independent variables experimentally. Thermodynamic potentials allow us to switch to more convenient variables like $(T, V)$ or $(T, p)$ while preserving all thermodynamic information. They are constructed via Legendre transformations.

### **1.1 Helmholtz Free Energy ($F$)**

*   **Motivation:** Describes systems at constant temperature $T$ and volume $V$ (e.g., system in contact with a heat bath at fixed volume).
*   **Definition:**
    $$
    \boxed{ F \equiv E - TS }
    $$
*   **Differential:** $dF = dE - d(TS) = dE - T dS - S dT$. Substituting $dE = T dS - p dV$:
    $$
    \boxed{ dF = -S dT - p dV }
    $$
*   **Natural Variables:** $(T, V)$. $F = F(T, V)$.
*   **Thermodynamic Quantities from F:**
    $$ S = -\left(\frac{\partial F}{\partial T}\right)_V, \quad p = -\left(\frac{\partial F}{\partial V}\right)_T $$
*   **Relation to Work:** For a quasi-static, isothermal process, $W = -\Delta F = F_i - F_f$. The work done *by* the system equals the *decrease* in its Helmholtz free energy.

### **1.2 Enthalpy ($H$)**

*   **Motivation:** Describes systems at constant pressure $p$ (e.g., open to atmosphere, piston with constant external force).
*   **Definition:**
    $$
    \boxed{ H \equiv E + pV }
    $$
*   **Differential:** $dH = dE + d(pV) = dE + p dV + V dp$. Substituting $dE = T dS - p dV$:
    $$
    \boxed{ dH = T dS + V dp }
    $$
*   **Natural Variables:** $(S, p)$. $H = H(S, p)$.
*   **Thermodynamic Quantities from H:**
    $$ T = \left(\frac{\partial H}{\partial S}\right)_p, \quad V = \left(\frac{\partial H}{\partial p}\right)_S $$
*   **Relation to Heat:** For a quasi-static process at constant pressure, $Q_p = dH_p$. Heat absorbed equals the change in enthalpy.
*   **Relation to Heat Capacity:** $C_p = (\partial H / \partial T)_p$.

### **1.3 Gibbs Free Energy ($G$)**

*   **Motivation:** Describes systems at constant temperature $T$ and constant pressure $p$ (e.g., system in contact with heat bath and pressure reservoir). Most relevant for chemical reactions.
*   **Definition:**
    $$
    \boxed{ G \equiv E - TS + pV = F + pV = H - TS }
    $$
*   **Differential:** $dG = dH - d(TS) = dH - T dS - S dT$. Substituting $dH = T dS + V dp$:
    $$
    \boxed{ dG = -S dT + V dp }
    $$
*   **Natural Variables:** $(T, p)$. $G = G(T, p)$.
*   **Thermodynamic Quantities from G:**
    $$ S = -\left(\frac{\partial G}{\partial T}\right)_p, \quad V = \left(\frac{\partial G}{\partial p}\right)_T $$

## **2. Equilibrium Conditions and Maxwell Relations (Lecture 13)**

### **2.1 Equilibrium Conditions (Minimization Principles)**

*   Isolated System (fixed E, V): Equilibrium $\iff S$ is maximum. $\Delta S \ge 0$.
*   System at fixed T, V: Equilibrium $\iff F$ is minimum. $\Delta F \le 0$.
*   System at fixed T, p: Equilibrium $\iff G$ is minimum. $\Delta G \le 0$.

### **2.2 Maxwell Relations**

*   These relations arise from the mathematical property that mixed second partial derivatives of state functions (the potentials $E, F, H, G$) are equal (e.g., $\partial^2 E / (\partial S \partial V) = \partial^2 E / (\partial V \partial S)$).
*   They provide useful connections between seemingly unrelated thermodynamic derivatives.
*   From $dE = T dS - p dV$: $\frac{\partial}{\partial V}\left(\frac{\partial E}{\partial S}\right)_V = \frac{\partial}{\partial S}\left(\frac{\partial E}{\partial V}\right)_S \implies \boxed{\left(\frac{\partial T}{\partial V}\right)_S = -\left(\frac{\partial p}{\partial S}\right)_V}$
*   From $dF = -S dT - p dV$: $\frac{\partial}{\partial V}\left(\frac{\partial F}{\partial T}\right)_V = \frac{\partial}{\partial T}\left(\frac{\partial F}{\partial V}\right)_T \implies \boxed{\left(\frac{\partial S}{\partial V}\right)_T = \left(\frac{\partial p}{\partial T}\right)_V}$
*   From $dH = T dS + V dp$: $\frac{\partial}{\partial p}\left(\frac{\partial H}{\partial S}\right)_p = \frac{\partial}{\partial S}\left(\frac{\partial H}{\partial p}\right)_S \implies \boxed{\left(\frac{\partial T}{\partial p}\right)_S = \left(\frac{\partial V}{\partial S}\right)_p}$
*   From $dG = -S dT + V dp$: $\frac{\partial}{\partial p}\left(\frac{\partial G}{\partial T}\right)_p = \frac{\partial}{\partial T}\left(\frac{\partial G}{\partial p}\right)_T \implies \boxed{-\left(\frac{\partial S}{\partial p}\right)_T = \left(\frac{\partial V}{\partial T}\right)_p}$

### **2.3 Application: $C_p - C_V$ Relation**

*   Goal: Find a general relation between $C_p = T(\partial S/\partial T)_p$ and $C_V = T(\partial S/\partial T)_V$.
*   Method: Express $dS$ in terms of $(T, V)$ and $(T, p)$, relate $dp$ to $dT, dV$, equate coefficients, and use Maxwell relations and definitions of compressibility $K_T = -\frac{1}{V}(\partial V/\partial p)_T$ and expansivity $\alpha_p = \frac{1}{V}(\partial V/\partial T)_p$.
*   Result:
    $$
    \boxed{ C_p - C_V = T V \frac{\alpha_p^2}{K_T} }
    $$
*   Since $T, V, K_T$ are generally positive, this shows $C_p \ge C_V$.

## **3. Free Expansion and Joule-Thomson Process (Lectures 14, 15)**

### **3.1 Free Expansion (Joule Expansion)**

*   Process: Gas expands into a vacuum within a thermally isolated container ($V_1 \to V_2$).
*   Constraints: $Q=0, W=0$.
*   First Law $\implies \Delta E = 0$. Internal energy is constant. $E(T_1, V_1) = E(T_2, V_2)$.
*   Temperature Change: Determined by the **Joule coefficient**:
    $$ \mu_J = \left(\frac{\partial T}{\partial V}\right)_E = -\frac{(\partial E/\partial V)_T}{C_V} = \frac{1}{C_V} \left[ p - T\left(\frac{\partial p}{\partial T}\right)_V \right] $$
   $T_2 - T_1 = \int_{V_1}^{V_2} \mu_J dV$.
*   Ideal Gas: $(\partial E/\partial V)_T = 0 \implies \mu_J = 0 \implies T_2 = T_1$. No temperature change.
*   van der Waals Gas: $\mu_J = -a / (c_v v^2) < 0$. Gas cools upon free expansion ($\Delta T < 0$).
*   Entropy Change: Process is irreversible. $\Delta S = \int_{V_1}^{V_2} (\partial S/\partial V)_E dV = \int_{V_1}^{V_2} (p/T) dV > 0$.

### **3.2 Joule-Thomson Process (Throttling)**

*   Process: Gas flows steadily from constant $p_1$ to constant $p_2$ ($p_2 < p_1$) through a porous plug or valve in a thermally isolated pipe.
*   Constraint: Analysis shows the process occurs at constant **enthalpy**. $H(T_1, p_1) = H(T_2, p_2)$.
*   Temperature Change: Determined by the **Joule-Thomson coefficient**:
    $$ \mu_{JT} = \left(\frac{\partial T}{\partial p}\right)_H = -\frac{(\partial H/\partial p)_T}{C_p} = \frac{1}{C_p} \left[ T\left(\frac{\partial V}{\partial T}\right)_p - V \right] = \frac{V}{C_p}(T \alpha_p - 1) $$
   $T_2 - T_1 = \int_{p_1}^{p_2} \mu_{JT} dp$. Since $\Delta p = p_2 - p_1 < 0$:
    *   Cooling ($\Delta T < 0$) if $\mu_{JT} > 0$ (requires $T \alpha_p > 1$).
    *   Heating ($\Delta T > 0$) if $\mu_{JT} < 0$ (requires $T \alpha_p < 1$).
*   Ideal Gas: $H = E+pV = E(T)+NT$. Depends only on $T$. Constant $H \implies$ constant $T$. $\mu_{JT}=0$.
*   Real Gases: $\mu_{JT}$ can be positive or negative, depending on $T$ and $p$. The locus $\mu_{JT}=0$ defines the **inversion curve**. Throttling is used for liquefaction by operating inside the inversion curve where cooling occurs.
*   Entropy Change: Process is irreversible. $dS = -(V/T)dp$ along path of constant $H$. $\Delta S = \int_{p_1}^{p_2} -(V/T) dp > 0$ since $p_2 < p_1$.

## **4. Heat Engines and Refrigerators (Lecture 16)**

### **4.1 Heat Engines**

*   Device operating in a cycle, converting heat into work.
*   Cycle: Absorbs heat $q_1$ from hot reservoir ($T_1$), performs work $W$, rejects heat $q_2$ to cold reservoir ($T_2 < T_1$).
*   First Law (cycle): $\Delta E = 0 \implies (q_1 - q_2) - W = 0 \implies W = q_1 - q_2$.
*   Second Law (cycle): $\Delta S_{total} = \Delta S_{eng} + \Delta S_{res1} + \Delta S_{res2} = 0 - q_1/T_1 + q_2/T_2 \ge 0$.
    $$ \frac{q_2}{T_2} \ge \frac{q_1}{T_1} $$
*   Efficiency: $\eta = W/q_1 = (q_1 - q_2)/q_1 = 1 - q_2/q_1$.
*   Maximum Efficiency (Carnot Efficiency): Achieved when process is reversible ($\Delta S_{total}=0$). $q_2/T_2 = q_1/T_1 \implies q_2/q_1 = T_2/T_1$.
    $$
    \boxed{ \eta \le 1 - \frac{T_2}{T_1} }, \quad \eta_{Carnot} = 1 - \frac{T_2}{T_1}
    $$
*   Kelvin Statement of 2nd Law: Impossible to construct a device whose *sole* effect is to convert heat entirely into work (requires $q_2=0$, which violates $\Delta S_{total} \ge 0$).

### **4.2 Refrigerators**

*   Device operating in a cycle, transferring heat from cold to hot using work input.
*   Cycle: Absorbs heat $q_2$ from cold reservoir ($T_2$), receives work input $W$, rejects heat $q_1$ to hot reservoir ($T_1 > T_2$).
*   First Law (cycle): $\Delta E = 0 \implies (q_2 - q_1) - (-W) = 0 \implies q_1 = q_2 + W$.
*   Second Law (cycle): $\Delta S_{total} = q_1/T_1 - q_2/T_2 \ge 0$.
    $$ \frac{q_1}{T_1} \ge \frac{q_2}{T_2} $$
*   Coefficient of Performance (COP): $K = q_2 / W = q_2 / (q_1 - q_2)$.
*   Maximum COP: Achieved when reversible. $q_1/T_1 = q_2/T_2$.
    $$
    \boxed{ K \le \frac{T_2}{T_1 - T_2} }, \quad K_{Carnot} = \frac{T_2}{T_1 - T_2}
    $$
*   Clausius Statement of 2nd Law: Impossible to construct a device whose *sole* effect is to transfer heat from a colder body to a hotter body (requires $W=0$, which violates $\Delta S_{total} \ge 0$).

### **4.3 Carnot Cycle**


The **Carnot cycle** is a theoretical, idealized thermodynamic cycle consisting of four reversible processes performed by a system (the "working substance", like a gas in a cylinder) operating between two heat reservoirs at different temperatures, a hot reservoir at $T_H$ and a cold reservoir at $T_C$ [1]. The cycle is designed to achieve the maximum possible efficiency for converting heat into work (as an engine) or for transferring heat using work (as a refrigerator) between these two temperatures [8].

The four stages are [1][2][6][7]:

1.  **Isothermal Expansion (A $\rightarrow$ B)**:
    *   **"Isothermal"** means the process occurs at a *constant temperature* [2][3]. In this step, the system is in thermal contact with the hot reservoir at $T_H$ [2][6].
    *   **"Expansion"** means the volume of the working substance increases [2]. For a gas, this means a piston moves outward.
    *   As the system expands, it does work on the surroundings [2]. To keep the temperature constant during this expansion (preventing it from cooling due to the work done), the system must absorb heat $Q_H$ from the hot reservoir [1][2][6]. This is a slow, quasi-static process [7].

2.  **Adiabatic Expansion (B $\rightarrow$ C)**:
    *   **"Adiabatic"** means the system is *thermally isolated*, so no heat is exchanged with the surroundings ($Q=0$) [2][3][5].
    *   **"Expansion"** again means the volume increases [2]. The system continues to do work as it expands [2].
    *   Since no heat enters the system but work is being done by the system, the internal energy must decrease. For most substances (like an ideal gas), a decrease in internal energy corresponds to a decrease in temperature [2]. So, the temperature drops from $T_H$ down to $T_C$ during this step [2][6]. This is also a slow, quasi-static process [3][7].

3.  **Isothermal Contraction (or Compression) (C $\rightarrow$ D)**:
    *   **"Isothermal"** means constant temperature, this time at the lower temperature $T_C$ [2][7]. The system is placed in thermal contact with the cold reservoir [2][7].
    *   **"Contraction/Compression"** means the volume decreases [2]. Work is done *on* the system by the surroundings (e.g., pushing a piston inward) [2].
    *   Compressing a system normally increases its temperature. To keep the temperature constant at $T_C$, the system must reject heat $Q_C$ to the cold reservoir [2][7][8]. This is a slow, quasi-static process [7].

4.  **Adiabatic Contraction (or Compression) (D $\rightarrow$ A)**:
    *   **"Adiabatic"** means thermally isolated again ($Q=0$) [2][5].
    *   **"Contraction/Compression"** means the volume continues to decrease [2]. Work is done *on* the system [5].
    *   Since work is done on the system and no heat can escape, the internal energy increases, causing the temperature to rise from $T_C$ back to the initial temperature $T_H$ [2][7]. This completes the cycle, returning the system to its starting state A [2][7][8]. This is also a slow, quasi-static process [7].

**Key Points:**

*   **Expansion:** Volume increases, the system typically does work.
*   **Contraction/Compression:** Volume decreases, work is typically done on the system.
*   **Isothermal:** Constant temperature, requires heat exchange with a reservoir to maintain it.
*   **Adiabatic:** No heat exchange, temperature changes as work is done.
*   **Reversible:** Each step is performed quasi-statically, meaning slowly enough that the system is always effectively in internal equilibrium, and the process can be reversed without any net change in the universe's entropy [1][5].

The net result of the cycle is that heat $Q_H$ is absorbed, heat $Q_C$ is rejected, and net work $W = Q_H - Q_C$ is performed by the system [8]. Because it is reversible, it achieves the maximum possible efficiency $\eta = 1 - T_C/T_H$ [4][8].

-----
Okay, let's review Homework 5, connecting it to the concepts from Phase 4 (Thermodynamic Potentials, Maxwell Relations, Joule-Thomson, Heat Engines).

\format

## **Homework 5 Core Principles Review**

### **1. Thermodynamic Potentials and Maxwell Relations (Problem 1)**

*   **Core Principle:** For systems involving work other than $p dV$, the fundamental thermodynamic identity and the definitions/differentials of potentials are modified. Maxwell relations can still be derived from the exactness of these potential differentials. Here, the work done on the rod is $dW = F dL$, where $F$ is tension and $L$ is length.
    $$ \boxed{ T dS = dE - F dL \quad \text{(Fundamental Identity for rod)} } $$
*   **Method:**
    *   **(a) Fundamental Relation:** Identify work as $FdL$ (work done *by* the system is $-FdL$, work done *on* the system is $+FdL$). Use $dE = TdS + dW_{on}$ to get $dE = TdS + FdL$, which rearranges to $TdS = dE - FdL$.
    *   **(b) Maxwell Relation:** Identify the need for a potential whose natural variables are $(T, L)$. This is analogous to $F(T, V)$ for a gas. Define the Helmholtz-like free energy for the rod: $F_{rod} = E - TS$. Calculate its differential: $dF_{rod} = dE - TdS - SdT = (TdS + FdL) - TdS - SdT = -SdT + FdL$. From the exactness of $dF_{rod}$, equate mixed partials: $\frac{\partial}{\partial L}\left(\frac{\partial F_{rod}}{\partial T}\right)_L = \frac{\partial}{\partial T}\left(\frac{\partial F_{rod}}{\partial L}\right)_T$. This gives the Maxwell relation:
        $$ \boxed{ -\left(\frac{\partial S}{\partial L}\right)_T = \left(\frac{\partial F}{\partial T}\right)_L } $$
        Substitute the given $F = aT^2(L-L_0)$ to find $(\partial S/\partial L)_T = -(\partial F/\partial T)_L = -2aT(L-L_0)$.
    *   **(c) Entropy Calculation:** Use $dS = (\partial S/\partial T)_L dT + (\partial S/\partial L)_T dL$. Identify $(\partial S/\partial T)_L = C_L/T = (bT)/T = b$. Substitute the result from (b) for $(\partial S/\partial L)_T$. Integrate $dS = b dT - 2aT(L-L_0)dL$ along a convenient path (e.g., $(T_0, L_0) \to (T, L_0) \to (T, L)$) to find $S(T, L) - S(T_0, L_0)$.
    *   **(d) Adiabatic Process:** For a quasi-static adiabatic process, $dS=0$. Integrate $dS=0$ using the expression from (c) to relate initial $(T_i, L_i)$ and final $(T_f, L_f)$ states.
    *   **(e) Heat Capacity $C_L(L, T)$:** Use $C_L = T(\partial S/\partial T)_L$. Need $\partial S/\partial T$ at arbitrary $L$. Use the general relation $(\partial C_L/\partial L)_T = T (\partial^2 S / \partial L \partial T)$. Use the Maxwell relation from (b) to relate this to $\partial^2 F / \partial T^2$. Integrate $(\partial C_L/\partial L)_T$ from $L_0$ to $L$ to find $C_L(L, T) - C_L(L_0, T)$.
    *   **(f) Alternative Entropy Calculation:** Calculate $\Delta S$ along a different path $(T_0, L_0) \to (T_0, L) \to (T, L)$ using the result from (e) for $C_L(T, L)$. Verify it gives the same result as (c), demonstrating $S$ is a state function.
*   **Connection to Phase 4:** Direct application of defining thermodynamic potentials for non-$pV$ work, deriving and using Maxwell relations, calculating entropy changes, analyzing adiabatic processes.

### **2. Joule-Thomson Process and Inversion Curve (Problem 2)**

*   **Core Principle:** The Joule-Thomson (throttling) process occurs at constant **enthalpy** $H = E+pV$. The temperature change during throttling is determined by the sign of the Joule-Thomson coefficient $\mu_{JT} = (\partial T/\partial p)_H$. The **inversion curve** is the locus of points in the $(T, p)$ plane where $\mu_{JT}=0$. Inside the curve, $\mu_{JT}>0$ (cooling); outside, $\mu_{JT}<0$ (heating). The condition $\mu_{JT}=0$ is equivalent to:
    $$ \boxed{ T \left(\frac{\partial V}{\partial T}\right)_p - V = 0 } $$
    or $T \alpha_p = 1$.
*   **Method:**
    1.  Start with the van der Waals equation: $(p+a/v^2)(v-b)=RT$ (using molar volume $v$).
    2.  Calculate the partial derivative $(\partial v/\partial T)_p$. This requires implicit differentiation.
    3.  Substitute this derivative into the inversion condition $T(\partial v/\partial T)_p - v = 0$.
    4.  Solve the resulting equation for $T$ as a function of $v$ (or $v$ as a function of $T$). This gives the inversion curve in the $(T, v)$ plane.
    5.  Substitute the expression for $v(T)$ back into the van der Waals equation to find the pressure $p$ along the inversion curve, yielding $p(T)$.
    6.  Convert $p(T)$ and $T$ to reduced variables $p' = p/p_c$, $T' = T/T_c$ using the given critical constants $p_c = a/(27b^2)$ and $T_c = 8a/(27Rb)$.
    7.  Sketch the resulting $p'(T')$ curve.
*   **Connection to Phase 4:** Direct application of the theory of the Joule-Thomson process, specifically finding the inversion curve for a non-ideal gas.

### **3. Refrigerators/Heat Pumps and Second Law Limits (Problem 3)**

*   **Core Principle:** A heat pump is a refrigerator cycle used for heating. It absorbs heat $Q_o$ from a cold source (outside, $T_o$) and delivers heat $Q_i$ to a hot sink (inside, $T_i$) using work input $W$. $Q_i = W + Q_o$. The maximum "heating" coefficient of performance is limited by the Second Law (Carnot limit).
*   **Method:**
    1.  Identify the goal: Maximize heat delivered $Q_i$ per unit work $W$, i.e., maximize the ratio $Q_i/W$.
    2.  Maximum performance occurs for a reversible (Carnot) cycle, where $\Delta S_{total} = 0$. For the reservoirs, this means $Q_i/T_i - Q_o/T_o = 0$, or $Q_o/Q_i = T_o/T_i$.
    3.  Use the First Law: $W = Q_i - Q_o$.
    4.  Substitute $Q_o = Q_i (T_o/T_i)$ into the First Law: $W = Q_i - Q_i(T_o/T_i) = Q_i (1 - T_o/T_i) = Q_i (T_i - T_o)/T_i$.
    5.  Calculate the desired ratio (maximum COP for heating):
        $$ \boxed{ \left(\frac{Q_i}{W}\right)_{max} = \frac{Q_i}{Q_i (T_i - T_o)/T_i} = \frac{T_i}{T_i - T_o} } $$
    6.  Plug in numerical values (remembering to convert Celsius to Kelvin: $T(K) = T(C) + 273.15$).
*   **Connection to Phase 4:** Application of the First and Second Laws to a refrigeration cycle operating as a heat pump, finding the thermodynamically limited maximum performance.

### **4. Heat Engines with Finite Reservoirs (Problem 4)**

*   **Core Principle:** When reservoirs are finite (bodies with heat capacity $C$), their temperature changes as heat is extracted/rejected. An engine operates between them until they reach a common final temperature $T_f$. The maximum work is obtained when the process is reversible ($\Delta S_{total}=0$).
*   **Method:**
    1.  **(a) Work Done:** Heat extracted from hot body (2): $Q_2 = C(T_2 - T_f)$. Heat rejected to cold body (1): $Q_1 = C(T_f - T_1)$. Work done $W = Q_2 - Q_1 = C(T_2 - T_f) - C(T_f - T_1) = C(T_1 + T_2 - 2T_f)$.
    2.  **(b) Entropy Condition:** For maximum work, the process must be reversible, so total entropy change is zero. $\Delta S_{total} = \Delta S_1 + \Delta S_2 = \int_{T_1}^{T_f} \frac{C dT}{T} + \int_{T_2}^{T_f} \frac{C dT}{T} = 0$.
    3.  Integrate: $C \ln(T_f/T_1) + C \ln(T_f/T_2) = 0 \implies \ln(T_f^2 / (T_1 T_2)) = 0 \implies T_f^2 = T_1 T_2$.
        $$ \boxed{ T_f = \sqrt{T_1 T_2} \quad \text{(for max work)} } $$
    4.  **(c) Maximum Work:** Substitute this $T_f$ into the expression for $W$ from part (a). $W_{max} = C(T_1 + T_2 - 2\sqrt{T_1 T_2}) = C(\sqrt{T_1} - \sqrt{T_2})^2$.
*   **Connection to Phase 4:** Applies First and Second Laws to heat engines where reservoir temperatures change. Links maximum work to the reversible condition $\Delta S_{total}=0$.

### **5. Statistical Interpretation of Second Law (Problem 5)**

*   **Core Principle:** Spontaneous processes that decrease entropy are extremely improbable, though not strictly impossible according to mechanics. The probability of observing such a fluctuation is related to the entropy change via Boltzmann's principle $P \propto \Omega = e^S$ (using $k_B=1$). The probability ratio of a final state (weight raised) to the initial state (weight down) is $P_f/P_i = \Omega_f / \Omega_i = e^{S_f - S_i} = e^{\Delta S}$.
*   **Method:**
    1.  Identify the initial state (weight down, water at temp T) and final state (weight up by $h$, water slightly colder).
    2.  Calculate the entropy change $\Delta S$ of the isolated system (water+weight) for the spontaneous process (weight rising, water cooling).
    3.  The weight gains potential energy $mgh$. This energy comes from the water (heat bath), so the water loses heat $Q = -mgh$.
    4.  Entropy change of the water (reservoir): $\Delta S_{water} = Q/T = -mgh/T$.
    5.  Entropy change of the weight (mechanical system) is 0.
    6.  Total entropy change for the fluctuation: $\Delta S = \Delta S_{water} = -mgh/T$.
    7.  Probability of fluctuation relative to initial state: $P_{fluctuation} \propto e^{\Delta S} = e^{-mgh/T}$.
    8.  Plug in numbers and calculate the extremely small probability.
*   **Connection to Phase 2/4:** Connects the macroscopic Second Law (entropy tends to increase) to the microscopic statistical definition ($S = \ln \Omega$) and the probability of fluctuations.

### **6. Idealized Engine Cycles (Gasoline Engine) (Problem 6)**

*   **Core Principle:** Analyzing a thermodynamic cycle involving adiabatic and constant-volume processes. Apply First Law and process relations to find efficiency.
*   **Method:**
    1.  Identify the steps: Adiabatic compression (a-b), Isochoric heating (b-c), Adiabatic expansion (c-d), Isochoric cooling (d-a).
    2.  Heat input occurs only during b-c: $Q_1 = Q_{bc} = \Delta E_{bc} + W_{bc}$. Since $V$ is constant, $W_{bc}=0$. $\Delta E_{bc} = C_V (T_c - T_b)$. $Q_1 = C_V (T_c - T_b)$.
    3.  Net work $W = W_{ad, ab} + W_{iso, bc} + W_{ad, cd} + W_{iso, da}$. $W_{iso}=0$. $W_{ad} = -\Delta E = -C_V \Delta T$.
    4.  $W_{net} = W_{ab} + W_{cd} = -C_V(T_b - T_a) - C_V(T_d - T_c) = C_V(T_a - T_b + T_c - T_d)$.
    5.  Alternatively, $W_{net} = Q_{net} = Q_{bc} + Q_{da} = C_V(T_c - T_b) + C_V(T_a - T_d)$. Matches.
    6.  Efficiency $\eta = W_{net} / Q_1 = C_V(T_a - T_b + T_c - T_d) / [C_V(T_c - T_b)] = 1 - (T_d - T_a)/(T_c - T_b)$.
    7.  Use adiabatic relations $T V^{\gamma-1} = \text{const}$: $T_a V_1^{\gamma-1} = T_b V_2^{\gamma-1}$ and $T_d V_1^{\gamma-1} = T_c V_2^{\gamma-1}$.
    8.  Divide these: $(T_d/T_a) = (T_c/T_b)$. Rearrange: $T_d = T_a (T_c/T_b)$.
    9.  Substitute into efficiency: $\eta = 1 - (T_a(T_c/T_b) - T_a) / (T_c - T_b) = 1 - T_a(T_c/T_b - 1) / (T_b(T_c/T_b - 1)) = 1 - T_a/T_b$.
    10. Use $T_a V_1^{\gamma-1} = T_b V_2^{\gamma-1} \implies T_a/T_b = (V_2/V_1)^{\gamma-1}$.
    11. Final efficiency: $\eta = 1 - (V_2/V_1)^{\gamma-1}$. Note $V_2<V_1$ in the diagram, so the formula in the solution has $V_1/V_2$. Let's use the diagram volumes: $V_a=V_1, V_b=V_2$. Then $T_a V_1^{\gamma-1} = T_b V_2^{\gamma-1} \implies T_a/T_b = (V_2/V_1)^{\gamma-1}$. The solution derived $\eta=1-(V_1/V_2)^{\gamma-1}$ which seems inconsistent with $V_2<V_1$. Let's re-check the solution's work expression derivation.
    12. Solution Work: $W = \frac{1}{\gamma-1}[(p_C V_1 - p_D V_2) + (p_A V_2 - p_B V_1)]$. This seems to mix volumes $V_1, V_2$ incorrectly between states. The derivation leading to $\eta = 1 - (V_1/V_2)^{1-\gamma} = 1 - (V_2/V_1)^{\gamma-1}$ is correct if $V_1$ is the larger volume and $V_2$ the smaller.
*   **Connection to Phase 4:** Analysis of a specific engine cycle (Otto cycle), application of First Law, adiabatic process relations.

### **7. Second Law Limits on Coupled Engines/Refrigerators (Problem 7)**

*   **Core Principle:** The maximum efficiency of a heat engine ($\eta_{max}=1-T_C/T_H$) and the maximum COP of a refrigerator ($K_{max}=T_C/(T_H-T_C)$) operating between $T_H$ and $T_C$ are fundamental limits imposed by the Second Law. No device can exceed these limits.
*   **Method:** Proof by contradiction.
    *   **(a)** Assume an engine E exists with $\eta_E > \eta_{max}$. Couple it to a Carnot refrigerator R operating between the same reservoirs. Arrange heat flows/work such that the work output of E exactly drives R ($W_E = W_R$). Show that the net effect of the combined device (E+R) is to transfer heat from the cold reservoir to the hot reservoir with no net work input, violating the Clausius statement of the Second Law.
    *   **(b)** Assume a refrigerator R exists with $K_R > K_{max}$. Couple it to a Carnot engine E. Arrange heat flows/work such that the work output of E drives R ($W_E = W_R$). Show that the net effect of the combined device (E+R) is to take heat from the hot reservoir and convert it entirely into work (with no net heat transfer to the cold reservoir), violating the Kelvin statement of the Second Law.
*   **Connection to Phase 4:** Directly tests the understanding and implications of the maximum efficiencies derived from the Second Law for engines and refrigerators.

This homework set thoroughly exercises the concepts of thermodynamic potentials, Maxwell relations, specific thermodynamic processes (Joule, Joule-Thomson), and the fundamental limits on energy conversion cycles imposed by the Second Law.

------



# **Phase 5: Canonical and Grand Canonical Ensembles (Lectures 18-21)**

This phase shifts back to the microscopic statistical approach, developing powerful tools (ensembles) for systems in contact with reservoirs, which are often easier to handle mathematically than the microcanonical ensemble. (Reif 6.1-6.7, 6.9).

## **1. Canonical Ensemble (CE) (Lectures 18, 19)**

### **1.1 Motivation and Setup**

*   The microcanonical ensemble describes isolated systems (fixed $E, V, N$).
*   Often, systems are *not* isolated but are in thermal contact with a much larger **heat reservoir** (or heat bath) which maintains the system at a constant **temperature** $T$.
*   The system of interest (A) can exchange energy with the reservoir (A'), so its energy $E_A$ is not fixed but fluctuates. The total energy $E^{(0)} = E_A + E_{A'}$ is conserved.
*   Goal: Find the probability $P_r$ that the system A is in a specific microstate $r$ having energy $E_r$.

### **1.2 Derivation of the Canonical Distribution**

*   Probability $P_r$ is proportional to the number of states accessible to the reservoir $\Omega'(E' = E^{(0)} - E_r)$.
    $$ P_r \propto \Omega'(E^{(0)} - E_r) = e^{S'(E^{(0)} - E_r)} $$
*   Since $E_r \ll E^{(0)}$, expand the reservoir's entropy $S'$:
    $S'(E^{(0)} - E_r) \approx S'(E^{(0)}) - (\partial S'/\partial E')_0 E_r = S'(E^{(0)}) - E_r/T$.
*   Substitute back: $P_r \propto e^{S'(E^{(0)})} e^{-E_r/T}$.
*   The probability of finding the system in microstate $r$ is:
    $$
    \boxed{ P_r = \frac{e^{-E_r/T}}{Z} = \frac{e^{-\beta E_r}}{Z} }
    $$
    where $\beta = 1/T$ (using $k_B=1$). This is the **Canonical (or Gibbs) Distribution**.

### **1.3 Partition Function ($Z$)**

*   The normalization constant $Z$ is the **Canonical Partition Function**:
    $$
    \boxed{ Z(T, V, N) = \sum_{\text{states } r} e^{-E_r(V, N)/T} }
    $$
*   The sum is over *all* possible microstates $r$ accessible to the system (with fixed $N, V$).
*   $Z$ contains all the statistical information about the system at fixed $T, V, N$.

### **1.4 Averages in the CE**

*   The ensemble average of an observable $O$ (whose value in state $r$ is $O_r$) is:
    $$ \bar{O} = \sum_r P_r O_r = \frac{1}{Z} \sum_r O_r e^{-\beta E_r} $$
*   **Average Energy:** $\bar{E} = \frac{1}{Z} \sum_r E_r e^{-\beta E_r}$. This can be conveniently calculated from $Z$:
    $$
    \boxed{ \bar{E} = -\frac{\partial (\ln Z)}{\partial \beta} }
    $$
*   **Energy Fluctuations:** The variance of energy is $\overline{(\Delta E)^2} = \overline{E^2} - (\bar{E})^2$.
    $$ \overline{(\Delta E)^2} = \frac{\partial^2 (\ln Z)}{\partial \beta^2} = -\frac{\partial \bar{E}}{\partial \beta} $$
    This can be related to the heat capacity:
    $$
    \boxed{ \overline{(\Delta E)^2} = T^2 C_V }
    $$
    The relative fluctuation $\sqrt{\overline{(\Delta E)^2}} / \bar{E} \propto 1/\sqrt{N}$, showing fluctuations are negligible for macroscopic systems.

## **2. Connection to Thermodynamics (CE) (Lectures 19, 20)**

### **2.1 Helmholtz Free Energy ($F$)**

*   The fundamental link between the statistical partition function $Z$ and macroscopic thermodynamics is through the Helmholtz Free Energy $F$:
    $$
    \boxed{ F(T, V, N) = -T \ln Z(T, V, N) }
    $$
*   This relation is central. Knowing $Z$ as a function of $T, V, N$ allows calculation of $F$, and from $F$, all other thermodynamic quantities can be found using standard relations.
*   From $dF = -S dT - p dV + \mu dN$:
    *   Entropy: $S = -(\partial F/\partial T)_{V,N} = T(\partial (\ln Z)/\partial T)_V + \ln Z$.
    *   Pressure: $p = -(\partial F/\partial V)_{T,N} = T(\partial (\ln Z)/\partial V)_{T,N}$.
    *   Chemical Potential: $\mu = (\partial F/\partial N)_{T,V} = -T(\partial (\ln Z)/\partial N)_{T,V}$.
*   Consistency Check: $F = \bar{E} - TS \implies \bar{E} = F + TS = (-T \ln Z) + T(T(\partial (\ln Z)/\partial T)_V + \ln Z) = T^2 (\partial (\ln Z)/\partial T)_V$. Using $T=1/\beta$, $dT = -d\beta/\beta^2$, this becomes $\bar{E} = (1/\beta^2) (-\beta^2) (\partial (\ln Z)/\partial \beta)_V = -\partial (\ln Z)/\partial \beta$. Matches the earlier result.

### **2.2 Equivalence of Ensembles**

*   For macroscopic systems, where fluctuations are negligible, the thermodynamic results obtained from the CE (at fixed T) are equivalent to those obtained from the MCE (at fixed E), provided the temperature $T$ in the CE is chosen such that the average energy $\bar{E}(T)$ equals the fixed energy $E$ of the MCE.
*   Similarly, $S_{CE}(\bar{E}) \approx S_{MCE}(\bar{E}) = \ln \Omega(\bar{E})$.
*   Practical implication: Calculations are often much easier in the CE (unrestricted sum for $Z$) than in the MCE (restricted sum/volume for $\Omega$).

## **3. Grand Canonical Ensemble (GCE) (Lecture 21)**

### **3.1 Motivation and Setup**

*   Needed for systems that can exchange both energy *and* particles with a large reservoir.
*   The reservoir fixes the system's temperature $T$ and **chemical potential** $\mu$. Volume $V$ is also fixed.
*   The system's energy $E_r$ and particle number $N_r$ fluctuate.
*   Goal: Find the probability $P_r$ of the system being in microstate $r$ (which has energy $E_r$ and particle number $N_r$).

### **3.2 Chemical Potential ($\mu$)**

*   From $dE = T dS - p dV + \mu dN$, the chemical potential is:
    $$ \mu = \left(\frac{\partial E}{\partial N}\right)_{S,V} = \left(\frac{\partial F}{\partial N}\right)_{T,V} = \left(\frac{\partial G}{\partial N}\right)_{T,p} $$
*   It represents the energy change (or free energy change) when adding one particle at constant $(S, V)$ or $(T, V)$, etc.
*   Equilibrium condition for particle exchange between systems 1 and 2: $\mu_1 = \mu_2$ (in addition to $T_1=T_2$).

### **3.3 Derivation of the Grand Canonical Distribution**

*   Similar derivation to CE, but now expand reservoir entropy $S'(E^{(0)}-E_r, N^{(0)}-N_r)$ for small $E_r, N_r$.
*   $S' \approx S'_0 - (\partial S'/\partial E')_0 E_r - (\partial S'/\partial N')_0 N_r = S'_0 - E_r/T - (-\mu/T)N_r$.
*   $P_r \propto e^{S'} \propto e^{-(E_r - \mu N_r)/T}$.
*   The probability of finding the system in microstate $r$ (with $N_r$ particles) is:
    $$
    \boxed{ P_r = \frac{e^{-(E_r - \mu N_r)/T}}{\mathcal{Z}} = \frac{e^{-\beta(E_r - \mu N_r)}}{\mathcal{Z}} }
    $$
    This is the **Grand Canonical Distribution**.

### **3.4 Grand Partition Function ($\mathcal{Z}$)**

*   The normalization constant $\mathcal{Z}$ is the **Grand Partition Function**:
    $$
    \boxed{ \mathcal{Z}(T, V, \mu) = \sum_{\text{states } r} e^{-(E_r - \mu N_r)/T} }
    $$
*   The sum is over *all* states, including states with different particle numbers $N_r$.
*   Alternatively, grouping by $N$:
    $$ \mathcal{Z}(T, V, \mu) = \sum_{N=0}^\infty e^{\beta \mu N} Z(T, V, N) $$
    where $Z(T, V, N)$ is the canonical partition function for exactly $N$ particles.

### **3.5 Grand Potential ($\Phi$)**

*   The corresponding thermodynamic potential is the **Grand Potential** $\Phi$ (sometimes denoted $\Omega$, but $\Omega$ is often used for number of states):
    $$
    \boxed{ \Phi(T, V, \mu) = -T \ln \mathcal{Z} }
    $$
*   Thermodynamic Identity: From $G = \mu N$, we have $F = G - pV = \mu N - pV$. Also $F = E - TS$. So $E - TS = \mu N - pV$. The grand potential is defined thermodynamically as $\Phi = F - \mu N = E - TS - \mu N$.
*   Differential: $d\Phi = dE - TdS - SdT - \mu dN - N d\mu$. Substituting $dE = TdS - pdV + \mu dN$:
    $$ d\Phi = (TdS - pdV + \mu dN) - TdS - SdT - \mu dN - N d\mu $$
    $$
    \boxed{ d\Phi = -S dT - p dV - N d\mu }
    $$
*   Thermodynamic Quantities from $\Phi$:
    *   $S = -(\partial \Phi / \partial T)_{V,\mu}$
    *   $p = -(\partial \Phi / \partial V)_{T,\mu}$ (Note: If $\Phi \propto V$, then $p = -\Phi/V$)
    *   Average Particle Number: $\bar{N} = -(\partial \Phi / \partial \mu)_{T,V}$.

This concludes Phase 5, establishing the canonical and grand canonical ensembles as powerful tools for systems in contact with thermal and/or particle reservoirs.

------

That's an excellent idea. Summarizing the key features of the three main ensembles side-by-side will be very helpful for clarity before moving on.

\format

## **Summary of Statistical Ensembles**

Here's a comparative overview of the Microcanonical, Canonical, and Grand Canonical ensembles:

| Feature                 | Microcanonical Ensemble (MCE)                    | Canonical Ensemble (CE)                                 | Grand Canonical Ensemble (GCE)                                           |
| :---------------------- | :----------------------------------------------- | :------------------------------------------------------ | :----------------------------------------------------------------------- |
| **System Type**         | Isolated                                         | Closed, Thermal Contact with Reservoir                  | Open, Thermal & Diffusive Contact with Reservoir                         |
| **Fixed Parameters**    | $E, V, N$                                        | $T, V, N$                                               | $T, V, \mu$                                                              |
| **Fluctuating Quantities**| (None - conceptually)                            | Energy ($E$)                                            | Energy ($E$), Particle Number ($N$)                                       |
| **Probability Law**     | $P_r = 1/\Omega(E)$ (for accessible states)      | $P_r = e^{-E_r/T} / Z$                                  | $P_r = e^{-(E_r-\mu N_r)/T} / \mathcal{Z}$                                |
| **Statistical Function**| $\Omega(E)$ = Number of States                   | $Z(T,V,N) = \sum_r e^{-E_r/T}$ (Partition Function)     | $\mathcal{Z}(T,V,\mu) = \sum_r e^{-(E_r-\mu N_r)/T}$ (Grand Part. Func.) |
| **Link to Thermodynamics**| $S = \ln \Omega$ (Entropy)                       | $F = -T \ln Z$ (Helmholtz Free Energy)                  | $\Phi = -T \ln \mathcal{Z}$ (Grand Potential)                            |
| **Thermodynamic Identity**| $dE = TdS - pdV$ (+$\mu dN$ if N varies)         | $dF = -SdT - pdV + \mu dN$                              | $d\Phi = -SdT - pdV - N d\mu$                                             |
| **Primary Use**         | Foundational concept, Defines S & T              | Constant T calculations, Often easier than MCE        | Systems with variable N, Quantum gases, Phase transitions                |
| **Equilibrium Condition**| $S$ is maximum                                   | $F$ is minimum (at const T, V)                          | $\Phi$ is minimum (at const T, V, $\mu$)                                 |

**Key Takeaway:** For macroscopic systems, all three ensembles yield equivalent results for thermodynamic averages. The choice of ensemble is typically based on mathematical convenience for the problem at hand. The CE and GCE are often preferred because their partition functions involve unrestricted sums over states, simplifying calculations compared to the energy-constrained sum in the MCE.

Now we are well-prepared to move into Phase 6, where we will apply these ensemble methods, particularly the CE and GCE, to understand classical and quantum statistics in more detail. 

----

Alright, let's begin Phase 6: Classical & Quantum Statistics, covering Lectures 22-25 and 27. This phase revisits the ideal gas using the canonical ensemble, addresses the Gibbs paradox formally, discusses the validity of the classical limit, introduces the equipartition theorem, and lays the groundwork for quantum statistics.

\format
No more than 3 spaces from the left margin, and display math must be followed by text on the same line, not a newline.

# **Phase 6: Classical & Quantum Statistics (Lectures 22-25, 27)**

This section applies the canonical ensemble to the ideal gas, formally addresses the Gibbs paradox and the need for the $N!$ correction, establishes the classical limit, introduces the equipartition theorem, and transitions to quantum statistics. (Reif 7.1-7.6, 9.1-9.2).

## **1. Ideal Gas Revisited (Canonical Ensemble) & Gibbs Paradox (Lecture 22)**

### **1.1 Classical Partition Function ($Z'$) - Initial Attempt**

*   We use the classical phase space integral for $N$ particles, initially treating them as distinguishable:
    $$ Z' = \int \frac{d^{3N}q d^{3N}p}{(2\pi\hbar)^{3N}} e^{-\beta E(q, p)} $$
*   For an ideal monatomic gas, $E(q, p) = K(p) = \sum_{i=1}^N \frac{|\vec{p}_i|^2}{2m}$. Interactions $U(q)=0$.
*   The integral factorizes into spatial and momentum parts:
    *   Spatial integral: $\int d^{3N}q = (\int d^3q)^N = V^N$.
    *   Momentum integral: $\left[ \int \frac{d^3p}{(2\pi\hbar)^3} e^{-\beta p^2/(2m)} \right]^N$.
*   The single-particle momentum integral evaluates to $1/\lambda_{th}^3$, where $\lambda_{th} = h/\sqrt{2\pi m T}$ is the thermal de Broglie wavelength.
*   Result for distinguishable particles:
    $$ Z' = V^N \left( \frac{1}{\lambda_{th}^3} \right)^N = \left( \frac{V}{\lambda_{th}^3} \right)^N = \xi^N $$
    where $\xi = V/\lambda_{th}^3$ is related to the single-particle partition function.

### **1.2 Thermodynamics from $Z'$ and the Gibbs Paradox**

*   Helmholtz Free Energy: $F' = -T \ln Z' = -N T \ln \xi = -N T \ln(V/\lambda_{th}^3)$.
*   Pressure $p = -(\partial F'/\partial V)_T = NT/V$. (Correct ideal gas law).
*   Energy $\bar{E} = -\partial(\ln Z')/\partial \beta = \frac{3}{2}NT$. (Correct energy).
*   Entropy $S' = -(\partial F'/\partial T)_V = N[\ln V + \frac{3}{2}\ln T + \text{const}]$.
*   **Problem (Gibbs Paradox):** This entropy $S'$ is *not extensive*. If we double the system ($N \to 2N, V \to 2V$ at constant $T$), $S'$ does not double ($S' \to 2S' + 2N \ln 2$). This leads to a non-zero entropy change when mixing two identical gases at the same $T, p$, which is unphysical.

### **1.3 Resolution: Indistinguishable Particles and Correct Partition Function ($Z$)**

*   **QM Principle:** Identical particles are fundamentally indistinguishable. Permuting identical particles does not lead to a new physical state.
*   **Correction:** The classical calculation overcounted the distinct states by treating permutations of identical particles as distinct. For $N$ particles, there are $N!$ such permutations. We must divide the classical phase space volume (or $Z'$) by $N!$.
*   **Correct Classical Partition Function for Identical Particles:**
    $$
    \boxed{
    Z = \frac{Z'}{N!} = \frac{1}{N!} \left( \frac{V}{\lambda_{th}^3} \right)^N
    }
    $$
*   **Correct Free Energy:** $F = -T \ln Z = -T (\ln Z' - \ln N!) \approx F' + T(N \ln N - N)$ (using Stirling's approx $\ln N! \approx N \ln N - N$).
    $$ F \approx -N T \left[ \ln\left(\frac{V}{N \lambda_{th}^3}\right) + 1 \right] $$
*   **Correct Entropy (Sackur-Tetrode Equation):** $S = -(\partial F/\partial T)_V$.
    $$
    \boxed{
    S = N \left[ \ln\left(\frac{V}{N \lambda_{th}^3}\right) + \frac{5}{2} \right]
    }
    $$
    This entropy *is* extensive ($S \propto N$ if $V/N$ is constant) and resolves the Gibbs paradox ($\Delta S_{mix}=0$ for identical gases at same $T, p$). The $N!$ factor is crucial and arises naturally from quantum statistics.

## **2. Validity of Classical Limit & Equipartition Theorem (Lecture 23)**

### **2.1 Validity of Classical Approximation**

*   When can we use the classical description (phase space integral with $N!$ correction)?
*   Compare the average interparticle separation $a \sim (V/N)^{1/3} = n^{-1/3}$ with the thermal de Broglie wavelength $\lambda_{th} = h/\sqrt{2\pi m T}$.
*   Classical limit is valid when particles are far apart compared to their thermal "size":
    $$ a \gg \lambda_{th} \quad \text{or equivalently} \quad \boxed{ n \lambda_{th}^3 \ll 1 } $$
    This corresponds to high temperature or low density. When $n \lambda_{th}^3 \gtrsim 1$, quantum effects (wave function overlap, statistics) become important.

### **2.2 Equipartition Theorem (Classical)**

*   **Statement:** In classical statistical mechanics, for a system in thermal equilibrium at temperature $T$, each degree of freedom (coordinate or momentum) that appears quadratically in the Hamiltonian contributes, on average, $\frac{1}{2}T$ to the internal energy $\bar{E}$ (using $k_B=1$).
*   **Derivation Sketch:** If $E = \epsilon(u) + \tilde{E}$ where $\epsilon(u) = \frac{1}{2}\kappa u^2$ and $\tilde{E}$ is independent of $u$. The partition function factorizes $Z = \xi_u \times \tilde{Z}$. The average energy associated with $u$ is $\bar{\epsilon} = -\partial(\ln \xi_u)/\partial \beta$. Calculating $\xi_u = C \int e^{-\beta \kappa u^2/2} du = C' \beta^{-1/2}$ gives $\ln \xi_u = \text{const} - \frac{1}{2}\ln \beta$. Then $\bar{\epsilon} = -(-\frac{1}{2\beta}) = \frac{1}{2\beta} = \frac{1}{2}T$.
*   **Applications:**
    *   Monatomic Ideal Gas: $E = \sum_{i=1}^N (p_{ix}^2+p_{iy}^2+p_{iz}^2)/(2m)$. $3N$ quadratic terms. $\bar{E} = 3N \times (\frac{1}{2}T) = \frac{3}{2}NT$. $C_V = \frac{3}{2}N$.
    *   1D Classical Harmonic Oscillator: $E = p^2/(2m) + \frac{1}{2}kq^2$. 2 quadratic terms. $\bar{E} = 2 \times (\frac{1}{2}T) = T$. $C = 1$.
*   **Limitation:** Equipartition is purely classical. It fails at low temperatures where quantum effects become important and degrees of freedom "freeze out" (e.g., vibrational modes in diatomic molecules, specific heat of solids).

## **3. Introduction to Quantum Statistics (Lecture 27)**

### **3.1 Identical Particles and Quantum States**

*   QM requires treating identical particles according to their statistics (symmetry of the many-body wavefunction under particle exchange).
*   **Bosons:** Integer spin (0, 1, 2,...). Wavefunction is symmetric under exchange. Any number of bosons can occupy the same single-particle state ($n_r = 0, 1, 2, \dots$). Examples: photons, ${}^4$He.
*   **Fermions:** Half-integer spin (1/2, 3/2,...). Wavefunction is antisymmetric under exchange. **Pauli Exclusion Principle**: No two identical fermions can occupy the same quantum state ($n_r = 0$ or $1$). Examples: electrons, protons, neutrons, ${}^3$He.

### **3.2 Occupation Numbers**

*   For non-interacting identical particles, a many-body state is specified by the set of **occupation numbers** $\{n_1, n_2, n_3, \dots\}$, where $n_r$ is the number of particles in the single-particle state $r$.
*   Total Energy: $E_{\{n_r\}} = \sum_r n_r \epsilon_r$, where $\epsilon_r$ is the energy of single-particle state $r$.
*   Total Particle Number: $N = \sum_r n_r$.

### **3.3 Partition Function in Terms of Occupation Numbers (Canonical)**

*   The canonical partition function involves summing over all possible sets of occupation numbers $\{n_r\}$ that satisfy the particle number constraint $\sum_r n_r = N$:
    $$ Z_N = \sum_{\{n_r\} \text{ s.t. } \sum n_r = N} e^{-\beta \sum_r n_r \epsilon_r} $$
*   The allowed values for each $n_r$ depend on whether the particles are bosons or fermions.
*   This constraint makes calculations in the CE difficult for quantum gases. The GCE is generally preferred.

This concludes Phase 6. We've seen the necessity of the $N!$ factor for classical ideal gases, understood its origin in particle indistinguishability, defined the classical limit, applied the equipartition theorem, and set up the framework for quantum statistics based on occupation numbers and particle type (boson/fermion). 

------




